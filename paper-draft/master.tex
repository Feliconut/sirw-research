%%%%%%%%%%%%%
% % Lines starting with % are comments, which are ignored.
% % This is a handy way of indicating the date and version of
% % your document, to wit:
% %
% % first draft, 2023_08_03
% % Modified  2023_08_06
% % Lastest Edition, 2023_08_06
% % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Title and author(s)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Scaling Limit of AF-SIRW for $p<\frac{1}{2}$.}
\author{ 
	Xiaoyu Liu
	\and
	Zhe Wang}

\date{Aug 6th, 2023}


% This is the definition of the type of document
\documentclass[twoside,12pt,a4paper]{article}
%\documentclass{article}

\usepackage[english]{babel}
\usepackage[margin=1.0 in]{geometry}
\usepackage[latin1]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fourier}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage[inline]{enumitem}
\usepackage{hyperref}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{remark}{Remark}
\newtheorem{scolium}{Scolium} [section]  
\newtheorem{definition}{Definition}[section]
\numberwithin{equation}{section}

%% This defines the "proo" environment, which is the same as proof, but
\newenvironment{proof}{{\sc Proof}:}{~\hfill $\square$}
\newenvironment{AMS}{}{}
\newenvironment{keywords}{}{}

%% Local macros
\newcommand{\abs}[1]{\left\vert #1 \right\vert}
\newcommand\TBD{\textcolor{red}{TBD.}}

\newcommand{\edt}[1]{\textcolor{blue}{#1}} %08.06.2023
\newcommand{\edtt}[1]{\textcolor{green}{#1}} %08.14.2023





\begin{document}
		\maketitle

\begin{abstract}
	This document is an outline of the article for the Scaling limit of SIRW. We generalize the functional CLT in \cite{KMP22} for the asymptotically free self-interacting random walk (AF-SIRW) in the case $0<p<\frac{1}{2}$ (possibly $p=\frac{1}{2}$). The approach is to carefully approximate the local drifts of the random walk via the study of the directed edge local times, which are described by branching-like processes and generalized Ray-knight Theorems. Xiaoyu Liu and Zhe Wang are working on this project. 
	\TBD
\end{abstract}

\section{Introduction}
The current project is a generalization of the result in \cite{KMP22}. 
\TBD 


\subsection{Model Description} 
We consider a discrete time nearest neighbor self-interaction random walk $(X_i)_{i\geq 0}$ on $\mathbb{Z}$ starting from site $x=0$ with transition probabilities depending on its edge local times and a (deterministic) weight function $w$ on $\mathbb{N}\cup \{0\}$. More precisely, let $w(.)$ be a monotone positive function on $\mathbb{N}_0$ satisfying

\begin{equation}\label{eq: asymptotics of w}
	\frac{1}{w(n)} = 1+\frac{2^p B}{n^p} + O\left(\frac{1}{n^{1+\mathcal{\chi}}}\right), \quad \mbox{as $n\to \infty$}, 	
\end{equation} 
The SIRW $(X_i)_{i\geq 0}$ has following dynamics, 
$X_0 = 0$, and for any $n\geq 0$
\begin{equation}\label{dynamic}
	\mathbb{P}\left( X_{n+1} =  X_n +1 | X_0,X_1,\dots,X_n   \right) =  \frac{  w(r(X_i,i) )}{ w(l(X_i,i))  + w(r(X_i,i))   },
\end{equation}
where $l(x,i)$ and $r(x,i)$ are the local times by time $i$ for the directed edges $(x,x-1)$ and $(x,x+1)$
$$ l(x,i) = \sum_{j=0}^{i-1} \mathbb{1}_{ \{  (X_j, X_{j+1}) =  (x,x-1) \} }, \mbox{ and }  r(x,i) = \sum_{j=0}^{i-1} \mathbb{1}_{ \{  (X_j, X_{j+1}) =  (x,x+1) \} }.        $$

The weight function $w(.)$ is referred to as the "cookie environment". In our case, the cookie environment is deterministic and identical for each site $x\in \mathbb{Z}$. \TBD (Add backgrounds on the model assumptions, especially why we use deterministic monotone function $w$, and why this is called asymptotically free case. )

\subsection{Main Result}
\begin{definition}
	Let $\theta_+, \theta_- <1$. A BMPE $W^{\theta_+, \theta_-} = \left(W^{\theta_+, \theta_-}_t, t\geq 0\right)$ with parameter  $(\theta_+, \theta_-)$ is the pathwise unique solution of the equation
	$$
	W_t = B_t + \theta_+ \cdot \sup_{s\leq t} W_s  + \theta_- \cdot \inf_{s\leq t} W_s,   \quad W_0 = 0.
	$$
\end{definition}
When the weight function $w(.)$ is monotone and satisfying \eqref{eq: asymptotics of w}, for any $p\in (0,1]$
\begin{equation}\label{eq: gamma}
	\gamma:= \lim_{n\to \infty}\left( V_1(n) - U_1(n) \right) =\lim_{n\to \infty} \left( \sum_{j=0}^{n-1} \frac{1}{ w(2j+1)}-  \sum_{j=0}^{n-1}  \frac{1}{w(2j)} \right) 
\end{equation}
is well defined and $\gamma<1$. It is shown, in Theorem 1.2 \cite{KMP22}, that when $p\in (\frac{1}{2},1]$, and $\mathcal{\chi} >0 $, the rescaled process
$$
 \left(  \frac{X_{\lfloor nt \rfloor }}{\sqrt{n}}  \right)_{t\geq 0} \Longrightarrow \left( W^{\gamma,\gamma}_{t}\right)_{t\geq 0},
$$ as $n$ goes to infinity in the standard Skorohod topology $D([0,\infty) ).$

Our main result is the functional limit theorem in the case when $p\in (0,\frac{1}{2})$.
\begin{theorem}\label{thm: main}
 Let $w(.)$ be monotone and satisfy \eqref{eq: asymptotics of w} for $p\in (0,\frac{1}{2})$, and $\mathcal{\chi} >0 $. Consider the SIRW $(X_n)_{n\geq 0}$ defined in \eqref{dynamic} with $X_0 =0$. Then the rescaled process
	 $$
	 \left(  \frac{X_{\lfloor nt \rfloor }}{\sqrt{n}}  \right)_{t\geq 0} \Longrightarrow \left( W^{\gamma,\gamma}_{t}\right)_{t\geq 0},
	 $$ as $n$ goes to infinity in the standard Skorohod topology $D([0,\infty) ).$
\end{theorem}
The proof of Theorem \ref{thm: main} follows a strategy similar to that Theorem 1.2 \cite{KMP22}, which relies on martingale methods, analysis of branching-like processes, and generalized Ray-Knight Theorems. This approach is classical in random walk in random environments \TBD, and it has also been used previously in other self-interacting random walk in dimension one, such as \TBD. The novelty of the current article is an approximation of accumulated local drifts $\Delta_y^{(x,m)}$, defined in section \ref{sec: proof of main} below on certain good events, which occurs with a high probability. On these good events, the accumulated local drifts are well approximated by their conditional means $\rho_{y}^{(x,m)}$ given certain edge local times $\mathcal{E}_y$, while their conditional means $\rho_{y}^{(x,m)}$ are close to the $\gamma \cdot sgn(y)$ when  $\mathcal{E}_y$ is large. \TBD These good events are closely related to the generalized P\'{o}lya  urn processes associated to sites, and we estimtate their probabilities by studying branching-like processes, which are derived from the original SIRW $(X_n)_{n\geq 0}$ via the generalized Ray-Knight Theorem. At this point, we also point out that the approximation of accumulated local drifts $\Delta_y^{(x,m)}$ is different from those in \cite{KMP22} since in the case when $p\in(\frac{1}{2},1]$, the conditional mean $\rho_{y}^{(x,m)}$ converges absolutely, which does not hold in the case when $p\leq \frac{1}{2}$. We need to construct certain good events on which the errors $\Delta_y^{(x,m)}- \rho_y^{(x,m)}$ are well-behaved.

\subsection{Organization of Paper}
In section \ref{sec: proof of main}, we prove Theorem \ref{thm: main} in several technical steps, each of which is stated as an individual proposition. In particular, the proofs of three technical results are postponed to section \ref{sec: approximations} because they involve analysis of auxiliary processes. In section \ref{sec: generalized Polya Urn, BLP}, we describe these auxiliary processes, generalized P\'{o}lya urn processes and branching-Like processes, discuss their connections to the SIRW $(X_n)$, and show some preliminary results related to technical results. In section \ref{sec: approximations}, we show the approximations of local drifts on good events as well as estimating their probabilities. 

\subsection{Notation}
We end this section by introducing some notations related to SIRW $(X_n)_{n\geq 0}$. To avoid confusion, the notations related to generalized P\'{o}lya urn, and branching-like processes are in section \ref{sec: generalized Polya Urn, BLP}.

For an SIRW $(X_n)_{n\geq 0}$,  let $(\mathcal{F}^X_n)_n$ be its natural filtration $\mathcal{F}^X_n = \sigma\left(X_i: i\leq n \right).$ We denote by $\mathbb{P}$ and $\mathbb{E}$ its probability and corresponding expectation. The following (random) quantities related to the SIRW $(X_n)_n$ are important in our analysis:
\begin{enumerate}
	\item the local time of site $x$ by time $j$, $L(x,j):= \sum_{i=0}^j \mathbb{1}_{\{X_i=x\} }$;
	
	\item the local time of directed bond $(x,x+1)$ by time $j$,
	$ \mathcal{E}^j_x = \sum_{i=0}^{j-1} \mathbb{1}_{\{X_i=x, X_{i+1} =x+1 \} } $; the local time of directed bond $(x,x+1)$ by time $j$ is $ D^j_x = \sum_{i=0}^{j-1} \mathbb{1}_{\{X_i=x, X_{i+1} =x-1 \} }; $
	
	
	\item the $m$-th visit time to site $x$, $\lambda_{x,m} = \inf\{t \geq 0: L(x,t) = m\}$;
	
	\item the running maximum of the process at time $n$, $M_n= \sup\{y: L(y,n)\geq 1 \} $; the minimum of the process at time $n$, $I_n= \inf\{y: L(y,n)\geq 1 \} $;
	
	\item the accumulated local drifts at site $x$ by time $k$, $$\delta_{x,m}:= \sum_{i=0}^\infty E[X_{i+1}-X_i\vert \mathcal{F}_{i}^X] \mathbb{1}_{\{X_i=x, L(x,i)\leq m\}};$$
	and the accumulated local drifts at site $x$ by time $\lambda_{x,m}$, 
	\begin{equation}\label{eq: accumulated local drift}
	\Delta_y^{x,m}:= \sum_{i=0}^{\lambda_{x,m}} E[X_{i+1}-X_i\vert \mathcal{F}_{i}^X] \mathbb{1}_{\{X_i=y\}}.
	\end{equation}
\end{enumerate}

\section{Proof of Theorem \ref{thm: main}}\label{sec: proof of main}
The proof of Theorem \ref{thm: main} follows a classical strategy in obtaining functional limit theorems. We will divide the proof in four main steps. We first decompose the random walk into
$X_n = M_n+ \Gamma_n, $ where
$$ 
\Gamma_0 = 0, \quad \Gamma_n = \sum_{i=0}^{n-1} \mathbb{E}\left[ X_{i+1}-X_i | \mathcal{F}_i^X \right]
$$ 

\textbf{Step 1: Control of martingale term.}
The choice of $\Gamma_n$ allows us to get a martingale $M_n$ with respect to $\mathcal{F}_i^X.$ Then the rescaled process $\frac{M_n}{\sqrt{n}}$ converges to a standard brownian motion in distribution if we have the control of martingales 
\begin{equation}\label{eq: QV term}
\lim_{n\to \infty}\frac{1}{n} \sum_{i=0}^{n-1}\mathbb{E}\left[ (M_{i+1}- M_{i})^2 |\mathcal{F}_i^X \right] =1,  \mbox{ in probability}.
\end{equation}
Since $\abs{X_{n+1}-X_n}=1$,  \eqref{eq: QV term} is implied by the estimate
\begin{proposition} \label{lm: control of martingale} Let $p\in (0,\frac{1}{2})$. Then, for any $\epsilon >0$
	\begin{equation}\label{eq:  term}
	\lim_{n \to \infty }\mathbb{P}\left(\frac{1}{n} \sum_{i = 0}^{n-1} \mathbb{E}\left[ X_{i+1} - X_i | \mathcal{F}_i \right]^2 > \epsilon \right) =0. 
\end{equation}
\end{proposition}
The proof of Proposition \ref{lm: control of martingale} is in section \ref{sec: approximations}.

\textbf{Step 2: Control of accumulated drift.} This is the major technical step of our article. We want to approximate the accumulated drift $\Gamma_n$ by a fixed linear combination of the distances between $X_n$ and its running maximum $S_n$ and minimum $I_n$:
\begin{proposition}\label{lm: control of acc drift}
	 Let $p\in (0,\frac{1}{2})$. Then, for any $t>0$ and any $\epsilon >0$
	\begin{equation}\label{eq: control of acc drift}
		\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\Gamma_k - \gamma \left(M_k - I_k \right)   } > \epsilon \sqrt{n}  \right) =0. 
	\end{equation}
\end{proposition}
To prove Proposition \ref{lm: control of acc drift}, we assume that $X_n=x \geq 0$, and $L(x,n)=m$. We decompose the accumulated drift as $\Gamma_n = 	\Gamma_n^+ +	\Gamma_n^0 + \Gamma_n^-$ 
\begin{align}
	\Gamma_n^+ &= \sum_{y > X_n} \sum_{i = 0}^{n-1} \mathbb{E}\left[ X_{i + 1} - X_i | \mathcal{F}_i^X \right] \mathbf{1}(X_i = y)\\
	\Gamma_n^0 &= \sum_{i = 0}^{n-1} \mathbb{E}\left[ X_{i + 1} - X_i | \mathcal{F}_i^X \right] \mathbf{1}(X_i = y) \\
	\Gamma_n^- &= \sum_{y < X_n} \sum_{i = 0}^{n-1} \mathbb{E}\left[ X_{i + 1} - X_i | \mathcal{F}_i^X \right] \mathbf{1}(X_i = y)
.\end{align} 
The contribution from $\Gamma_n^0$ is negligible (\TBD). We only need to consider the term $\Gamma_n^+$ while the contribution from $\Gamma_n^-$ \textcolor{red}{almost follows a symmetric argument}. (\TBD) 

In view of \eqref{eq: accumulated local drift}, $\Gamma_n^+$ is the sum 
$$
\Gamma_n^+ = \sum_{y>x} \Delta_y^{(x,m)}.
$$ which has $(M_n - X_n)$ terms. If we can further approximate terms $\Delta_y^{(x,m)}$ by $\gamma$ without generating a total error of size $\epsilon \sqrt{n}$, $\Gamma_n^+$ is approximately 
$$   
 \gamma (M_n - X_n).
$$
More precisely,for any $t>0$ and any $\epsilon >0$
\begin{equation}\label{eq: control of acc drift + }
	\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\Gamma^+_k - \gamma \left(M_k - X_k \right)   }\cdot \mathbb{1}_{\{X_k\geq 0 \}} > \epsilon \sqrt{n}  \right) =0. 
\end{equation}
To this end, we consider the filtration $\left(\mathcal{G}_{y}^{(x,m)}\right)_{y\geq x}$, where $ \mathcal{G}_{y}^{(x,m)} = \sigma\left( \mathcal{E}^{n}_y : y \geq x \right)$, and further approximate $\Delta_y^{(x,m)}$ by its conditional mean with respect to $\mathcal{G}_{y-1}^{(x,m)}$,
\begin{equation}\label{eq: conditional mean}
	\rho_{y}^{(x,m)}= \mathbb{E}\left[\Delta_y^{(x,m)} | \mathcal{G}_{y-1}^{(x,m)}\right].
\end{equation}
Then \eqref{eq: control of acc drift + } follows from the following two propositions:
\begin{proposition}\label{lm: approximation of means of local drift}
		Let $p\in (0,\frac{1}{2})$. Then, for any $t>0$ and any $\epsilon >0$
		\begin{equation}\label{eq: control of expected local drift}
			\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\sum_{y> X_k} \left( \rho_{y}^{(x,m)} - \gamma  \right)   }\cdot\mathbb{1}_{\{X_k\geq 0\}} > \epsilon \sqrt{n}  \right) =0. 
		\end{equation}
\end{proposition}
and
\begin{proposition}\label{lm: approx local drift by conditional means}
	Let $p\in (0,\frac{1}{2})$. Then, for any $t>0$ and any $\epsilon >0$
	\begin{equation}\label{eq: control of martingale difference for local drift}
		\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\sum_{y> X_k} \left(\Delta_{y}^{(x,m)}- \rho_{y}^{(x,m)} \right)   } \cdot\mathbb{1}_{\{X_k\geq 0\}} > \epsilon \sqrt{n}  \right) =0. 
	\end{equation}
\end{proposition}
The proofs of both Propositions \ref{lm: approximation of means of local drift} and \ref{lm: approx local drift by conditional means} involve auxiliary processes associated to the SIRW $(X_n)_{n\geq 0}$: the generalized P\'{o}lya Urn process, and branching-like processes. Both rely on considering approximating $\Delta_{y}^{(x,m)}$ on certain good events. The good events in the proof of Proposition \ref{lm: approximation of means of local drift} are easier because events like Lemma 2.2 in \cite{KMP22} will almost do the job, and estimates of their probabilities are essentially known from \cite{KMP22}. However, the good events for Proposition \ref{lm: approx local drift by conditional means} requires a new construction, and estimating the error requires a new proof, which is the major novelty of this article. We will postpone their proofs to section \ref{sec: approximations} after a more detailed description of the generalized P\'{o}lya Urn process, and branching-like processes.

\TBD With a slight effort, we extend \eqref{eq: control of acc drift + } for $\Gamma_k^+$ to $\Gamma_k^-$, and obtain Proposition \ref{lm: control of acc drift}.


\textbf{Step 3: Tightness.} \TBD This follows from (\cite{KMP22}, Proposition~2.1).

\textbf{Step 4: Convergence to BMPE.} \TBD The proof follows word by word.

\section{Generalized P\'{o}lya Urn, Branching-Like Processes, and Preleminary Results}\label{sec: generalized Polya Urn, BLP}
\TBD In this section, we describe the auxiliary processes related to the SIRW $(X_n)_{n\geq 0}$, and prove some of their properties which aids our proofs of Propositions \ref{lm: control of martingale}, \ref{lm: approximation of means of local drift}, and \ref{lm: approx local drift by conditional means}.
\subsection{Generalized P\'{o}lya  Urn}
Given a random walk $(X_n)_{n\geq 0}$, and a fixed site $y\in \mathbb{Z}$, (since $(X_n)_{n\geq 0}$ is recurrent,) we can obtain a generalized P\'{o}lya urn process associated to site $y$ by considering only up-crossings and down-crossings of $X_i$ from $y$. Due to the markov property, the sequence of $\left(\mathcal{E}^{\lambda_{y,k}}_y, \mathcal{D}^{\lambda_{y,k}}_y\right)_{k\geq 0}$ is a Markov process in $k$. Alternatively, we can use general weights $\{b(i)\}_{i\geq 0}$, $\{r(j)\}_{j\geq 0}$ and Rubin's construction to get a generalized P\'{o}lya urn process $(\mathcal{B}_k,\mathcal{R}_k)_k$. It is not hard to see that $\left(\mathcal{E}^{\lambda_{y,k}}_y, \mathcal{D}^{\lambda_{y,k}}_y\right)_{k\geq 0}$ has the same distribution as $(\mathcal{B}_k,\mathcal{R}_k)_k$ when the general weights are chose appropriately. We have the following notation related to a generalized P\'{o}lya urn process $(\mathcal{B}_k,\mathcal{R}_k)_k$:
\begin{enumerate}
	\item General weights $\{b(i)\}_{i\geq 0}$, $\{r(j)\}_{j\geq 0}$ 
	
	\item Transition probabilities 
	$$ P\left((\mathcal{B}_{k+1},\mathcal{R}_{k+1})=  (i+1,j) \vert (\mathcal{B}_{k},\mathcal{R}_{k}) =(i,j)  \right) = \frac{b(i)}{b(i)+r(j)},$$ and $$
	P\left((\mathcal{B}_{k+1},\mathcal{R}_{k+1})=  (i,j+1) \vert (\mathcal{B}_{k},\mathcal{R}_{k}) =(i,j)  \right) = \frac{r(j)}{b(i)+r(j)}.$$ 
	
	\item The number of trials until a blue/red ball is selected for the $k$-th time,
	$$ \tau^B_k = \inf\{ l\geq 0: \mathcal{B}_{l} =k   \}  \mbox{, and } \tau^R_k = \inf\{ l\geq 0: \mathcal{R}_{l} =k .  \}
	$$
	Note that $\tau^B_k, \tau^R_k$ are defined inductively in \cite{KMP22}. We assume $(\mathcal{B}_{0},\mathcal{R}_{0}) =(0,0) $ here to avoid confusion.
	
	\item The number of red balls drawn before the $k$-th blue ball, $\mu(k)$. Assuming that the initial condition is $(\mathcal{B}_{0},\mathcal{R}_{0}) = (0,0) $, $ \mu(k) =\tau^B_k - k$. 
	
	\item The signed difference at a time $k$, $\mathcal{D}_k =\mathcal{R}_k -\mathcal{B}_k.  $ 
	
\end{enumerate}

\subsection{Branching-Like Processes}
\TBD
The branching-like processes can be derived from the local times of directed edges of SIRW $(X_n)_{n\geq 0}$ at certain stopping times. Alternatively, we can use two sequences of BLPs $\zeta$ and $\tilde{\zeta}$ with a site $x\in \mathbb{Z}$ and an integer $m\geq 0$ to generate local times inductively from $x$. (Due to symmetry, we can assume $x\geq 0$.) In particular, these BLPs $\zeta$ and $\tilde{\zeta}$ are Markov processes, and the transition probabilities are given in terms of the generalized P\'{o}lya urn processes, see equations (63), (64) in \cite{KMP22}. We have the following related notation:
\begin{enumerate}
	\item Assume that $x\geq 0$, $\mathcal{G}^{(x,m)}_{z}:= \sigma( \mathcal{E}^{(x,m)}_y: x\leq y\leq z ).$ 
	
	\item Let
	$$
	\rho_y^{(x,m)} := E[ \Delta_y^{(x,m)} \vert \mathcal{G}^{(x,m)}_{y-1}].
	$$ Although, $\Delta_y^{(x,m)}$ is not $\mathcal{G}^{(x,m)}_{y-1}$ or $\mathcal{G}^{(x,m)}_{y}$ measurable, it's bounded by $ L(y, \lambda_{x,m} ) = \mathcal{E}^{(x,m)}_y + D_y^{(x,m)} = \mathcal{E}^{(x,m)}_y + \mathcal{E}^{(x,m)}_{y-1} $ which is $\mathcal{G}^{(x,m)}_{y}$- measurable.
\end{enumerate}

\subsection{Preliminary Results}
To facilitate our arguments in section \ref{sec: approximations}, we list three \textcolor{red}{(or four)} results from \cite{KMP22,T96}, whose proofs \textcolor{red}{we omit at this moment.}

The first result is a concentration inequality for $\mathcal{D}_i$ in a generalized P\'{o}lya urn process. This lemma is a major tool in estimating the probability of good events.
\begin{lemma}(Lemma 4.1 \cite{KMP22})\label{lm: concentration inequality}
	Let weights $r(i) = w(2i)$, $b(i)= w(2i+1) $ for all $i\geq 0$. Then there exists constants $C,c>0$ such that for $k, m \in \mathbb{N}$,
	$$
	P\left(  \abs{ \mathcal{D}_{\tau_k^B}   } \geq m \right) \leq C e^{\frac{-cm^2}{m \vee k}}.
	$$
\end{lemma} 
Lemma \ref{lm: concentration inequality} remains valid for the generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})$ associated to sites $y<0$ and $y=0$. For these two cases, the sequence of weights $(r(i),b(i))$ are slightly different. When $y<0$, $r(i) = w(2i+1)$, $b(i)= w(2i) $; when $y=0$, $r(i) = b(i)=w(2i)$.

The second result is an identity for a generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})_k$. Recall that $\mu(k)= \tau^B_k - k$, for all $k\geq 1$. 
\begin{lemma}(Lemma 1, \cite{T96}) \label{lm: Toth's Identity}
	For any $m\in \mathbb{N}$ and $\lambda < \min\{ b(j): 0\leq j\leq m-1 \}$, we have the following identity,
	$$  \mathbb{E}\left[  \prod_{j=0}^{ \mu(m)-1 } \left(1+ \frac{\lambda}{r(j)}   \right) \right] =   \prod_{j=0}^{ m-1 } \left(1- \frac{\lambda}{b(j)}   \right)^{-1}.   $$ 
	In particular, 
	\begin{equation}\label{eq: Toth's Identity 1}
		\mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}   \right] =   \sum_{j=0}^{ m-1 } \frac{1}{b(j)}.
	\end{equation}	
\end{lemma}
\eqref{eq: Toth's Identity 1} is a direct consequence of the first identity. And the first identity can be proved via (exponential) martingales associated to the generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})$, 
$$M_k(\lambda) = \prod_{i=0}^{ \mathcal{B}_{k}-1 } \left(1-\frac{\lambda}{b(i)}\right) \prod_{j=0}^{\mathcal{R}_{k}-1 } \left(1+\frac{\lambda}{r(j)}\right). $$

\TBD \textcolor{red}{We can put the process level tightness of extrema result here if we do not plan to give a proof of it. Since we need it to bound the range of the process in the proofs of Propositions \ref{lm: approximation of means of local drift}, \ref{lm: approx local drift by conditional means}, we should quote it or prove it somewhere in the paper.}  

The last result is a control of the number of sites with "small" local times:
\begin{lemma}(Lemma 2.2 \cite{KMP22})\label{lm: number of rarely visit sites}
	Let $\alpha =0$, and $\gamma_+ = \gamma \vee 0$. Then for any $M>0$, and any $b>\frac{\gamma_+}{2}$ we have
	$$
	\lim_{n\to\infty} P\left(\sup_{k\leq nt}  \sum_{x\in [I^X_{k-1}, S^X_{k-1}]} \mathbb{1}_{\{ L(x,k-1) \leq M \}} \geq 4n^b \right) = 0.
	$$
	
\end{lemma}	
Lemma \ref{lm: number of rarely visit sites} is a technical result, and its proof involves the analysis of BLPs and the concentration inequality in Lemma \ref{lm: concentration inequality} for the generalized P\'{o}lya urn process. The statement of Lemma \ref{lm: number of rarely visit sites} remains in force if we replace the range $[I_{k-1}, M_{k-1}]$ by $[X_k,M_k]$ (or $[I_{k-1},X_k]$ respectively), and replace the local times $L(x,k-1)$ by the numbers of up-crossings $\mathcal{E}^{k}_x$ (or $D^{k}_x$ respectively). In fact, these two extended results are partial steps in the proof of Lemma 2.2 in \cite{KMP22}.   


\section{Approximations of Local Drifts}\label{sec: approximations}
In this section, we will prove the technical propositions in the proof of Theorem \ref{thm: main}. \TBD


\subsection{Convergence of conditional Expectation}
In view of the generalized P\'{o}lya urn process (associated to a site $y> x$), 
$$\rho^{(x,m)}_y = E[\mathcal{D}_{\tau_L^B}], $$ where
$ L = \mathcal{E}^{(x,m)}_{y-1}$ is the number of up-crossing at site $y-1$ at time $\lambda_{x,m}$.
On one hand, $M_{nt} \leq K\sqrt{n} $ for some $K>0$ with a high probability; on the other hand, Lemma \ref{lm: number of rarely visit sites} says that, up to $n^b$ sites, (where $\frac{\gamma \vee 0}{2}<b<\frac{1}{2}$,) every site $y$ between $X_k=x$ and $\mathcal{M}^{(x,m)} =S_{k}^X$ has $ \mathcal{E}^{(x,m)}_{y-1} \geq M  $ with a high probability. To show Proposition \ref{lm: approximation of means of local drift}, it suffices to show 
\begin{equation}\label{eq: convergence of conditional expectation}
	\lim_{M\to\infty} E[\mathcal{D}_{\tau_M^B}] = \gamma , 
\end{equation} for positive sites. A symmetric argument allows us to get the factor $sgn(y)$ for sites $y<0$ and $y=0$.

\begin{lemma} \label{lm: convergence of mean of discrepancies}
For the generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})$ with weights $r(i)= w(2i)$, $b(i) = w(2i+1)$ for all $i\geq 0$, we have that
$$
\lim_{M\to\infty} E[\mathcal{D}_{\tau_M^B}] = \gamma. 
$$
\end{lemma} 
\begin{proof} 
	 We start from \eqref{eq: gamma} and identity \eqref{eq: Toth's Identity 1}. For any $m \geq 10$,
	 \begin{align}
	 	 V_1(m) - U_1(m) =& \sum_{i=0}^{m-1} \frac{1}{w(2i+1)} -\sum_{i=0}^{m-1} \frac{1}{w(2i)} 
	 	 \notag \\
	 	 =& \sum_{i=0}^{m-1} \frac{1}{b(i)} -\sum_{i=0}^{m-1} \frac{1}{r(i)} 
	 	 \notag \\
	 	 =& 	\mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}   \right] - \sum_{i=0}^{m-1} \frac{1}{r(i)} = \mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}    - \sum_{i=0}^{m-1} \frac{1}{r(i)}\right]. \label{eq: difference}
	 \end{align}
	From \eqref{eq: asymptotics of w}, we have that $0< \inf \frac{1}{r(j)} \leq \sup \frac{1}{r(j)} <\infty $, then $\mathbb{E}\left[\mu(m)\right]$ is bounded by
	$$\mathbb{E}\left[ \mu(m) \right] = \mathbb{E}\left[ \mu(m)\mathbb{1}_{\mu(m)\geq 1} \right] \leq  \frac{1}{\inf 1/w(j) }\mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}   \right] <\infty, $$ 
	so $ \mathbb{E}\left[ \mu(m) -m\right]  $ is bounded.
The difference in \eqref{eq: difference} can be written as
\begin{align} 
	\sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)} - \sum_{i=0}^{m-1} \frac{1}{r(i)} =& \sum_{j=m}^{\mu(m)-1} \left(\frac{1}{r(j)} -\frac{1}{r(m)} \right) \cdot\mathbb{1}_{\{\mu(m)\geq m\}} 
		\label{eq: 1st term}
		\\	
	& - \sum_{j=\mu(m)}^{m-1} \left(\frac{1}{r(j)} -\frac{1}{r(m)} \right) \mathbb{1}_{\{\mu(m)< m\}} 
	\label{eq: 2nd term}
		\\
	& + \frac{\mu(m)-m}{ r(m) }. \label{eq: major term}
\end{align} 
Since $\mu(m)-m =  \mathcal{D}_{\tau^B_m}$, the last term \eqref{eq: major term} is exactly $\frac{1}{r(m)} \mathcal{D}_{\tau^B_m}$, which has an expectation $\frac{1}{r(m)} \mathbb{E}\left[\mathcal{D}_{\tau^B_m}\right].$ Both \eqref{eq: 1st term} and \eqref{eq: 2nd term} have finite expectations, which vanish as $m$ goes to infinity:

 Indeed, let $A> \frac{2}{c} \vee 1$, where $c$ is from Lemma \ref{lm: concentration inequality}. \eqref{eq: 1st term} is bounded by
\begin{align}
	\sum_{j=m}^{\infty} \left(\abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \cdot \mathbb{1}_{\{\mu(m)\geq j \}}\right) & \leq  \sum_{0\leq j-m \leq A \sqrt{m}\log m } \left(\abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \cdot \mathbb{1}_{\{\mu(m)\geq j \}}\right) 
	\notag
	\\
	& +  \sum_{j-m > A\sqrt{m}\log m } \left(\abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \cdot \mathbb{1}_{\{\mu(m)\geq j \}}\right)
	\notag
	\\
	&\leq  \sum_{0\leq j-m \leq A\sqrt{m}\log m } \abs{\frac{1}{r(j)} -\frac{1}{r(m)} }
	\label{low difference}
	\\
	& + 2\left(\sup_j \frac{1}{w(j)}\right) \cdot \sum_{j\geq m + A\sqrt{m}\log m } \mathbb{1}_{\{ \mu(m) > j \}}
	\label{large difference}
\end{align}
In view of \eqref{eq: asymptotics of w}, there is a constant $C'>0$ such that for any $m>100 $ and any $j$ with $\abs{j-m}\leq A \sqrt m \log m $, 
$$ \abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \leq C' A m^{-p-\frac{1}{2}} \log m, $$
which implies that \eqref{low difference} is bounded by
$$
C' A^2 m^{-p} (\log m)^2.
$$ On the other hand, Lemma \ref{lm: concentration inequality} implies that the expectation of \eqref{large difference} is bounded by
\begin{align*}
 & 2\left(\sup_j \frac{1}{w(j)}\right) \sum_{j-m \geq A \sqrt m \log m  } P( \mathcal{D}_{\tau^B_m} \geq j-m )  
 \notag 
 \\
 \leq& 2\left(\sup_j \frac{1}{w(j)}\right) \sum_{l \geq A \sqrt m \log m } C \exp\left( - \frac{c  \cdot l^2}{l \vee m}   \right)
 \notag\\
 \leq& C'' \left( \exp (- cA^2 \cdot \log m ) + \exp(-cA \cdot \log m) \right), 
\end{align*} for some $C''$ independent of $m$. Therefore, the expectation of \eqref{eq: 1st term} is bounded by
\begin{equation}\label{boound}
	C' A^2 m^{-p} \log m + C''  \left( m ^{-cA^2} +  m^{-cA} \right). 
\end{equation}
One can treat \eqref{eq: 2nd term} similarly. 

With our choice of $A >\frac{2}{c} \vee 1$, \eqref{eq: difference}, \eqref{eq: 1st term}, \eqref{eq: 2nd term}, \eqref{eq: major term}, and \eqref{boound}, we get that
$$ \abs{ V_1(m)- U_1(m) -\frac{1}{r(m)}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] }
\leq 2C' A^2 m^{-p} \log m + 2C''  \left( m ^{-cA^2} +  m^{-cA} \right), 
$$ which converges to $0$ as $m$ goes to infinity. We conclude that
$$
\lim_{m\to\infty}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] = \gamma, 
$$ from $\lim_{m\to\infty}\frac{1}{r(m)} =1$ and $ \lim_{m\to \infty} \left(V_1(m)-U_1(m) \right) = \gamma$.
\end{proof}

For the generalized P\'{o}lya urn process associated to a site $y<0$, we have $r(i) = w(2i+1)$, $b(i) =w(2i)$. The right hand side of \eqref{eq: difference} is the same as $U_1(m)-V_1(m)$, which converges to $-\gamma$ as $m$ goes to infinity. Then we get that  $$\lim_{m\to\infty}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] = -\gamma.$$
Similarly, for $y=0$, the associated generalized P\'{o}lya urn process has 
$$\lim_{m\to\infty}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] = 0.$$

\TBD \textcolor{red}{We will need to define $\rho$ for negative sites.} We extend the definition of $\rho^{(x,m)}_y$ for sites $y< x$ by symmetry, 
$$\rho^{(x,m)}_y := \mathbb{E}\left[  \Delta^{(x,m)}_y   \left\vert  \sigma\left( D^{(x,m)}_z:  y<z\leq  x  \right. \right) \right].   $$ In terms of the generalized P\'{o}lya urn process associated to the site $y$,
\begin{equation} \label{eq: extended definition}
	\rho^{(x,m)}_y = \mathbb{E}\left[\mathcal{D}_{\tau_L^R}\right], 
\end{equation} where $L = D^{(x,m)}_{y+1} = \mathcal{E}^{(x,m)}_{y}.$ With an argument similar to the proof of Lemma \ref{lm: convergence of mean of discrepancies}, we get that 
\begin{equation}\label{eq: mean of discrepancies for left sites}
\lim_{L\to \infty} \mathbb{E}\left[\mathcal{D}_{\tau_L^R}\right] =  sgn(y) \cdot \gamma = \lim_{L\to \infty} \mathbb{E}\left[\mathcal{D}_{\tau_L^B}\right].
\end{equation}

Now we show Proposition \ref{lm: approximation of means of local drift} and a slightly stronger result. 
\begin{lemma}
	Let $w(.)$ be a positive monotone function on $\mathbb{N}_0$ satisfying \eqref{eq: asymptotics of w}. Then for any $0<p<1$, any $\epsilon>0$,
	$$
	\lim_{n\to\infty} P\left( \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,S_{k}^X]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}     \right) =0.
	$$
	Furthermore,
		$$
	\lim_{n\to\infty} P\left( \sup_{k\leq n t}  \abs{  	\sum_{y\in [I_k^{X} ,S_{k}^X]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}     \right) =0.
	$$
\end{lemma}
\begin{proof} First, there are only three types of weight sequences for the generalized P\'{o}lya urn processes associtated to sites $y>0$, $y=0$ and $y<0$. Therefore, from Lemma \ref{lm: convergence of mean of discrepancies}, and \eqref{eq: mean of discrepancies for left sites}, there is a decreasing function $C(.)$ on $\mathbb{N}_0$ with $\lim_{L\to \infty}C(L) =0$ such that for any $y \in \mathbb{Z}$,
	\begin{equation}\label{eq: uniform convergence}
		\abs{\mathbb{E}\left[ \mathcal{D}_{\tau_L^R} \right] - \gamma \cdot sgn(y)}, \abs{\mathbb{E}\left[ \mathcal{D}_{\tau_L^B} \right] - \gamma \cdot sgn(y)} \leq C(L).
	\end{equation} One such function is $C(l) = \sup \left\{  \abs{\mathbb{E}\left[ \mathcal{D}_{\tau_m^R} \right] - \gamma \cdot sgn(y)} + \abs{\mathbb{E}\left[ \mathcal{D}_{\tau_m^B} \right] - \gamma \cdot sgn(y)} : m\geq l \right\}.     $  
	
	
	Let $t>0$, and $b \in [\frac{\gamma \vee 0 }{2},\frac{1}{2})$.  For any $n,K,M>0$, we consider three types of events, 
	$$A_{n,K}:=\left\{ \min\{-I_{nt}, M_{nt}\} \geq K \sqrt{n}  \right\}$$
	$$B_{n,M}:= \left\{  \sup_{k\leq n t} \sum_{ y\in (X_{k-1}, M_{k-1}]}  \mathbb{1}_{\{ \mathcal{E}^{k-1}_{y-1} \leq M  \}} >n^b  \right\},  $$
	and 
	$$B'_{n,M}:=  \left\{  \sup_{k\leq n t} \sum_{ y\in [I_{k-1}, X_{k-1})}  \mathbb{1}_{\{ \mathcal{D}^{k-1}_{y+1} \leq M  \}} >n^b  \right\}.$$
Clearly, $A_{n,K}$ is decreasing in $K$, and $B_{n,M}, B'_{n,M}$ are increasing in $M$. We claim that for $n$ large, the event 
$$
F_{n,\epsilon}:= \left\{ \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,M_k]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}    \right \}$$ is contained in $A_{n,K} \cup B_{n,M} $ for some finite $K, M$ independent of $n$:   

	Indeed, depending on $(\mathcal{E}^{k-1}_{y-1} \leq M)$, terms  $\left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right)$ are bounded by $C(0)$ or $C(M)$. Therefore, the supremum is bounded by
	\begin{align*}
	 \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,M_k]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \leq &  
	 C(0) \cdot \sup_{k\leq n t} \left\{   	\sum_{y\in [X_{k}+1 ,M_k]} \mathbb{1}_{ \{ \mathcal{E}^{k-1}_{y-1} \leq M \} } \right\}
	 \notag
	 \\
	 +& C(M) \cdot \sup_{k\leq n t} \left\{   	\sum_{y\in [X_{k}+1 ,M_k]} \mathbb{1}_{ \{ \mathcal{E}^{k-1}_{y-1} \geq M \} } \right\},
\end{align*} which is bounded on $A^c_{n,K} \cap B^c_{n,M}$ by
\begin{equation}\label{eq: an upper bound on good set}
	C(0)n^b  + C(M) \left(K \sqrt{n} -n^b\right).
\end{equation} Clearly, \eqref{eq: an upper bound on good set} is smaller than $\epsilon \sqrt{n}$ for any $K>0$ and any $M$ with $C(M) < \frac{\epsilon}{2K}$. 
For such pairs of $(K,M)$, $A^c_{n,K} \cap B^c_{n,M} \subset F^c_{n,\epsilon}$, and 
$$
\limsup_{n\to \infty} P(F_{n,\epsilon}) \leq \limsup_{n\to \infty}  P(A_{n,K}) +  \limsup_{n\to \infty}  P(B_{n,M}).
$$ In view of Lemma \ref{lm: number of rarely visit sites} and the explanation after it, the second term $$\limsup_{n\to \infty}  P(B_{n,M})=0.$$  The first term $\limsup_{n\to \infty}  P(A_{n,K}) $ vanishes as $K$ goes to infinity, which is a consequence of Proposition 2.1 \cite{KMP22}, or Corollary 1A \cite{T96}.
 
The proof of 
$$  
\lim_{n\to\infty} P\left( \sup_{k\leq n t}  \abs{  	\sum_{y\in [I_k ,M_k]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}     \right) =0
$$ 
follows a similar argument. In particular, if we replace the range from $[X_k+1, M_k]$ by $[I_k,M_k]$, the event 
$$
\tilde{F}_{n,\epsilon}:= \left\{ \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,M_{k}]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}    \right \}
$$ 
is contained in $A_{n,K} \cup B_{n,M} \cup  B'_{n,M},$ for any $K>0$, and $M$ with $C(M) < \frac{\epsilon}{4K}$.
\end{proof}

\eqref{eq: an upper bound on good set} can be used as a crude estimate for 	$\sum_{y\in [X_{k}+1 ,M_{k}]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right)$   on the "good sets" $A^c_{n,K}\cap B^c_{n,M}$.

\subsection{Approximation of Local Drifts by Conditional Means}
In this subsection, we prove Proposition \ref{lm: approx local drift by conditional means}. \textcolor{red}{\TBD. Its proof is composed of by an argument for equation (16) in Xiaoyu's \cite{L23}, and an argument similar to that on page 20 of \cite{KP16}.}

\subsection{Control of martingale Terms } 
In this subsection, we prove Proposition \ref{lm: control of martingale}.\textcolor{red}{\TBD. Its proof is a similar to the proof of Proposition \ref{lm: approx local drift by conditional means}. An argument on page 15 of Xiaoyu's \cite{L23} should work.}

\begin{thebibliography}{99}\addcontentsline{toc}{chapter}{Bibliography} 
 \bibitem[KMP22]{KMP22} Kosygina,~E., Mountford,~T., Peterson,~J.: Convergence and Non-Convergence of Scaled Self-Interacting Random Walks to Brownian Motion Perturbed at Extrema. \textit{arXiv:2208.02589,} 2022.
 
 \bibitem[KP16]{KP16} Kosygina,~E., Peterson,~J.: Functional limit laws for recurrent excited random walks with
 periodic cookie stacks. \textit{Electron. J. Probab.} \textbf{21} 2016.

\bibitem[L23]{L23} Liu,~X.: Research in Random Walk. \textit{Personal communication,} 2023.

\bibitem[T96]{T96} T\'{o}th,~B.: Generalized Ray-Knight theory and limit theorems for self-interacting random walks on $\mathbb{Z}^1$ \textit{Ann. Probab.} \textbf{24} 1324--1367. 1996
\end{thebibliography}
\end{document}

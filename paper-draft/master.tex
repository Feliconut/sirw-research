%%%%%%%%%%%%%
% % Lines starting with % are comments, which are ignored.
% % This is a handy way of indicating the date and version of
% % your document, to wit:
% %
% % first draft, 2023_08_03
% % Modified  2023_08_30
% % Lastest Edition, 2023_08_30
% % Description of changes:
% % (1) Minor updates of fomulas and descriptions in subsection 1.4 and (2.5).
% % (2) Major changes are in section 3, subsection 3.1: 
% % 1)  the connection between $\Delta_{y}^{(x,m)}$ and the URN process is reworked; an argument for (3.6). 
% % 
% % Changes to be made: 
% % (1) Section 2, and subsction 3.2: 
% %  1) rework of descriptions after proposition 2.2, especially a focus on lambda_{x,m} instead of time k: 
% %  2) Motivations and comparison for 2.2
% %  3) description of construction of the BLP process.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Title and author(s)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Scaling Limit of AF-SIRW for $p\leq\frac{1}{2}$.}
\author{ 
	Xiaoyu Liu
	\and
	Zhe Wang}

\date{Aug 31st, 2023}


% This is the definition of the type of document
\documentclass[twoside,12pt,a4paper]{article}
%\documentclass{article}

\usepackage[english]{babel}
\usepackage[margin=1.0 in]{geometry}
\usepackage[latin1]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fourier}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage[inline]{enumitem}
\usepackage{hyperref}
\usepackage{mathrsfs}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{remark}{Remark}
\newtheorem{scolium}{Scolium} [section]  
\newtheorem{definition}{Definition}[section]
\numberwithin{equation}{section}

%% This defines the "proo" environment, which is the same as proof, but
\newenvironment{proof}[1][Proof]{{\sc #1}:}{~\hfill $\square$}
\newenvironment{AMS}{}{}
\newenvironment{keywords}{}{}

%% Local macros
\newcommand{\abs}[1]{\left\vert #1 \right\vert}
\newcommand\TBD{\textcolor{red}{TBD.}}
\newcommand{\edt}[1]{\textcolor{red}{#1}} %edit time 08/25/2023
\newcommand{\comment}[1]{\textcolor{blue}{#1}}




\begin{document}
	\maketitle
	
	\begin{abstract}
		This document is an outline of the article for the Scaling limit of SIRW. We complete the functional CLT in \cite{KMP22} for the asymptotically free self-interacting random walk (AF-SIRW) in the case $0<p \leq \frac{1}{2}$. The approach is to carefully approximate the local drifts of the random walk via the study of the directed edge local times, which are described by branching-like processes and generalized Ray-knight Theorems. Xiaoyu Liu and Zhe Wang are working on this project. 
		\TBD
	\end{abstract}
	
	\underline{\textsf{Information about the draft:}}
	\begin{itemize}
		\item 
	\textsf{\color{red} Red text, include \TBD marks, are pending works and existing problems.}
		\item 
			\textsf{\color{blue} Blue texts are comments or tentative ideas that can be discussed.}
	\end{itemize}

	
	\section{Introduction}
	The current project is a completion of Theorem 1.2 in \cite{KMP22}. 
	\TBD 
	
	
	\subsection{Model Description} 
	We consider a discrete time nearest neighbor self-interaction random walk $(X_i)_{i\geq 0}$ on $\mathbb{Z}$ starting from site $x=0$ with transition probabilities depending on its edge local times and a (deterministic) weight function $w$ on $\mathbb{N}\cup \{0\}$. More precisely, let $w(.)$ be a monotone positive function on $\mathbb{N}_0$ satisfying
	
	
	\begin{equation}\label{eq: asymptotics of w}
		\frac{1}{w(n)} = 1+\frac{2^p B}{n^p} + O\left(\frac{1}{n^{1+\mathcal{\chi}}}\right), \quad \mbox{as $n\to \infty$}, 	
	\end{equation} 
	The SIRW $(X_i)_{i\geq 0}$ has following dynamics, 
	$X_0 = 0$, and for any $n\geq 0$
	\begin{equation}\label{dynamic}
		\mathbb{P}\left( X_{n+1} =  X_n +1 | X_0,X_1,\dots,X_n   \right) =  \frac{  w(r(X_i,i) )}{ w(l(X_i,i))  + w(r(X_i,i))   },
	\end{equation}
	where $l(x,i)$ and $r(x,i)$ are the local times by time $i$ for the undirected edges $\{x,x-1\}$ and $\{x,x+1\}$
	$$ l(x,i) = \sum_{j=0}^{i-1} \mathbb{1}_{ \{  \{X_j, X_{j+1}\} =  \{x,x-1\} \} }, \mbox{ and }  r(x,i) = \sum_{j=0}^{i-1} \mathbb{1}_{ \{  \{X_j, X_{j+1}\} =  \{x,x+1\} \} }.        $$
	
	In our case, the weight function $w(.)$ is deterministic and identical for each site $x\in \mathbb{Z}$. \TBD (Add backgrounds on the model assumptions, especially why we use deterministic monotone function $w$, and why this is called asymptotically free case. )
	
	\subsection{Main Result}
	\begin{definition}
		Let $\theta_+, \theta_- <1$. A BMPE $W^{\theta_+, \theta_-} = \left(W^{\theta_+, \theta_-}_t, t\geq 0\right)$ with parameter  $(\theta_+, \theta_-)$ is the pathwise unique solution of the equation
		$$
		W_t = B_t + \theta_+ \cdot \sup_{s\leq t} W_s  + \theta_- \cdot \inf_{s\leq t} W_s,   \quad W_0 = 0.
		$$
	\end{definition}
	When the weight function $w(.)$ is monotone and satisfying \eqref{eq: asymptotics of w}, for any $p\in (0,1]$
	\begin{equation}\label{eq: gamma}
		\gamma:= \lim_{n\to \infty}\left( V_1(n) - U_1(n) \right) =\lim_{n\to \infty} \left( \sum_{j=0}^{n-1} \frac{1}{ w(2j+1)}-  \sum_{j=0}^{n-1}  \frac{1}{w(2j)} \right) 
	\end{equation}
	is well defined and $\gamma<1$. It is shown, in Theorem 1.2 \cite{KMP22}, that when $p\in (\frac{1}{2},1]$, and $\mathcal{\chi} >0 $, the rescaled process
	$$
	\left(  \frac{X_{\lfloor nt \rfloor }}{\sqrt{n}}  \right)_{t\geq 0} \Longrightarrow \left( W^{\gamma,\gamma}_{t}\right)_{t\geq 0},
	$$ as $n$ goes to infinity in the standard Skorohod topology $D([0,\infty) ).$
	
	Our main result is the functional limit theorem in the case when $p\in (0,\frac{1}{2})$.
	\begin{theorem}\label{thm: main}
		Let $w(.)$ be monotone and satisfy \eqref{eq: asymptotics of w} for $p\in (0,\frac{1}{2}]$, and $\mathcal{\chi} >0 $. Consider the SIRW $(X_n)_{n\geq 0}$ defined in \eqref{dynamic} with $X_0 =0$. Then the rescaled process
		$$
		\left(  \frac{X_{\lfloor nt \rfloor }}{\sqrt{n}}  \right)_{t\geq 0} \Longrightarrow \left( W^{\gamma,\gamma}_{t}\right)_{t\geq 0},
		$$ as $n$ goes to infinity in the standard Skorohod topology $D([0,\infty) ).$
	\end{theorem}
	The proof of Theorem \ref{thm: main} follows a strategy similar to that of Theorem 1.2 \cite{KMP22}, which relies on martingale methods, analysis of branching-like processes, and generalized Ray-Knight Theorems. This approach is classical in random walk in random environments \TBD, and it has also been used previously in other self-interacting random walk in dimension one, such as \TBD. The novelty of the current article is an approximation of accumulated local drifts $\Delta_y^{(x,m)}$, defined in section \ref{sec: proof of main} below on certain good events, which occurs with a high probability. On these good events, the accumulated local drifts are well approximated by their conditional means $\rho_{y}^{(x,m)}$ given certain edge local times, while their conditional means $\rho_{y}^{(x,m)}$ are close to the $\gamma \cdot sgn(y)$ when certain edge local time is large. \TBD These good events are closely related to the generalized P\'{o}lya  urn processes associated to sites, and we estimtate their probabilities by studying branching-like processes, which are derived from the original SIRW $(X_n)_{n\geq 0}$ via the generalized Ray-Knight Theorem. At this point, we also point out that the approximation of accumulated local drifts $\Delta_y^{(x,m)}$ is different from those in \cite{KMP22} since in the case when $p\in(\frac{1}{2},1]$, the conditional mean $\rho_{y}^{(x,m)}$ converges absolutely, which does not hold in the case when $p\leq \frac{1}{2}$. We need to construct certain good events on which the errors $\Delta_y^{(x,m)}- \rho_y^{(x,m)}$ are well-behaved.
	
	\subsection{Organization of Paper}
	In section \ref{sec: proof of main}, we prove Theorem \ref{thm: main} in several technical steps, each of which is stated as an individual proposition. In particular, the proofs of three technical results are postponed to section \ref{sec: approximations} because they involve analysis of auxiliary processes. In section \ref{sec: generalized Polya Urn, BLP}, we describe these auxiliary processes, generalized P\'{o}lya urn processes and branching-Like processes, discuss their connections to the SIRW $(X_n)$, and show some preliminary results related to technical results. In section \ref{sec: approximations}, we show the approximations of local drifts on good events as well as estimating their probabilities. 
	
	\subsection{Notation}
	We end this section by introducing some notations related to SIRW $(X_n)_{n\geq 0}$. To avoid confusion, the notations related to generalized P\'{o}lya urn, and branching-like processes are in section \ref{sec: generalized Polya Urn, BLP}.
	
	For an SIRW $(X_n)_{n\geq 0}$,  let $(\mathcal{F}^X_n)_n$ be its natural filtration $\mathcal{F}^X_n = \sigma\left(X_i: i\leq n \right).$ We denote by $\mathbb{P}$ and $\mathbb{E}$ its probability and corresponding expectation. The following (random) quantities related to the SIRW $(X_n)_{n\geq0}$ are important in our analysis:
	\begin{enumerate}
		\item for any $x \in \mathbb{Z}$, and $j\in \mathbb{N}_0$, the local time of a site $x$ by time $j$, $L(x,j):= \sum_{i=0}^j \mathbb{1}_{\{X_i=x\} }$; % the definition for local time in \cite{KMP22} and \cite{KP16} are different by at most 1. The main difference comes from whether to count the last step $X_n$. For the former case, $L(x,\lambda_{x,m}) = m+1$, while $L(x,\lambda_{x,m}) =m$ for the latter case.  
		
		\item the local time of directed bond $(x,x+1)$ by time $j\in \mathbb{N}_0$,
		$ \mathcal{E}^j_{x,+} = \sum_{i=0}^{j-1} \mathbb{1}_{\{X_i=x, X_{i+1} =x+1 \} } $; the local time of directed bond $(x,x-1)$ by time $j$ is $ \mathcal{E}^j_{x,-} = \sum_{i=0}^{j-1} \mathbb{1}_{\{X_i=x, X_{i+1} =x-1 \} }; $
		
		
		\item for any $m\geq 0$, the \edt{$m+1$}-th visit time to site $x$, $\lambda_{x,m} = \inf\{t \geq 0: L(x,t) = \edt{m+1} \}$;
		
		\item the running maximum of the process at time $n$, $M_n= \sup\{y: L(y,n)\geq 1 \} $; the minimum of the process at time $n$, $I_n= \inf\{y: L(y,n)\geq 1 \} $;
		
		\item 
%		the accumulated local drifts at site $x$ by $m$-th visit, $$\delta_{x,m}:= \sum_{i=0}^\infty E[X_{i+1}-X_i\vert \mathcal{F}_{i}^X] \mathbb{1}_{\{X_i=x, L(x,i)\leq m\}};$$ 
		the accumulated local drifts at site $x$ by time $\lambda_{x,m}$, 
		\begin{equation}\label{eq: accumulated local drift}
			\Delta_y^{(x,m)}:= \sum_{i=0}^{\lambda_{x,m}-1} E[X_{i+1}-X_i\vert \mathcal{F}_{i}^X] \mathbb{1}_{\{X_i=y\}}.
		\end{equation}
	\end{enumerate}
	
	\section{Outline for the Proof of Theorem \ref{thm: main}}\label{sec: proof of main}
	The proof of Theorem \ref{thm: main} follows a classical strategy in obtaining functional limit theorems. We will divide the proof in four main steps. We first decompose the random walk into
	$$X_n = M_n+ \Gamma_n, $$ where
	$$ 
	\Gamma_0 = 0, \quad \Gamma_n = \sum_{i=0}^{n-1} \mathbb{E}\left[ X_{i+1}-X_i | \mathcal{F}_i^X \right].
	$$ 
	
	\textbf{Step 1: Control of martingale term.}
	The choice of $\Gamma_n$ allows us to get a martingale $M_n$ with respect to $\mathcal{F}_i^X.$ Then the rescaled process $\frac{M_n}{\sqrt{n}}$ converges to a standard brownian motion in distribution if we have the control of martingales 
	\begin{equation}\label{eq: QV term}
		\lim_{n\to \infty}\frac{1}{n} \sum_{i=0}^{n-1}\mathbb{E}\left[ (M_{i+1}- M_{i})^2 |\mathcal{F}_i^X \right] =1,  \mbox{ in probability}.
	\end{equation}
	Since $\abs{X_{n+1}-X_n}=1$,  \eqref{eq: QV term} is implied by the estimate
	\begin{proposition} \label{lm: control of martingale} Let $p\in (0,\frac{1}{2}]$. Then, for any $\epsilon >0$
		\begin{equation}\label{eq:  term}
			\lim_{n \to \infty }\mathbb{P}\left(\frac{1}{n} \sum_{i = 0}^{n-1} \mathbb{E}\left[ X_{i+1} - X_i | \mathcal{F}_i \right]^2 > \epsilon \right) =0. 
		\end{equation}
	\end{proposition}
	The proof of Proposition \ref{lm: control of martingale} is in section \ref{sec: approximations}.
	
	\textbf{Step 2: Control of accumulated drift.} This is the major technical step of our article. We want to approximate the accumulated drift $\Gamma_n$ by a fixed linear combination of the distances between $X_n$ and its running maximum $S_n$ and minimum $I_n$:
	\begin{proposition}\label{lm: control of acc drift}
		Let $p\in (0,\frac{1}{2}]$. Then, for any $t>0$ and any $\epsilon >0$
		\begin{equation}\label{eq: control of acc drift}
			\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\Gamma_k - \gamma \left(M_k + I_k \right)   } > \epsilon \sqrt{n}  \right) =0. 
		\end{equation}
	\end{proposition}
	To prove Proposition \ref{lm: control of acc drift}, we assume that $X_k=x $, and $L(x,k)=m$. We decompose the accumulated drift as $\Gamma_k = 	\Gamma_k^+ +	\Gamma_k^0 + \Gamma_k^-$ 
	\begin{align}
		\Gamma_k^+ &= \sum_{y > X_k} \sum_{i = 0}^{k-1} \mathbb{E}\left[ X_{i + 1} - X_i | \mathcal{F}_i^X \right] \mathbf{1}(X_i = y)\\
		\Gamma_k^0 &= \sum_{i = 0}^{k-1} \mathbb{E}\left[ X_{i + 1} - X_i | \mathcal{F}_i^X \right] \mathbf{1}(X_i = X_k) \\
		\Gamma_k^- &= \sum_{y < X_k} \sum_{i = 0}^{k-1} \mathbb{E}\left[ X_{i + 1} - X_i | \mathcal{F}_i^X \right] \mathbf{1}(X_i = y)
		.\end{align} 
	The contribution from $\Gamma_n^0$ is negligible (\TBD). We only need to consider the term $\Gamma_n^+$ while the contribution from $\Gamma_k^-$ \textcolor{red}{almost follows a symmetric argument}. (\TBD) 
	
	In view of \eqref{eq: accumulated local drift} and $X_k=x$, $\Gamma_k^+$ is the sum 
	$$
	\Gamma_k^+ = \sum_{y>x} \Delta_y^{(x,m)}.
	$$ which has $(M_k - X_k)$ terms. If we can further approximate terms $\Delta_y^{(x,m)}$ by $\gamma\cdot sgn(y)$ without generating a total error of size $\epsilon \sqrt{n}$, $\Gamma_k^+$ is approximately 
	$$   
	\gamma \cdot (M_k - \abs{X_k}).
	$$
	More precisely, for any $t>0$ and any $\epsilon >0$
	\begin{equation}\label{eq: control of acc drift + }
		\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\Gamma^+_k - \gamma \left(M_k - \abs{X_k} \right)   } > \epsilon \sqrt{n}  \right) =0. 
	\end{equation}
	To this end, we consider the filtration $\left(\mathcal{G}_{y}^{(x,m)}\right)_{y\geq x}$, where $ \mathcal{G}_{y}^{(x,m)} = \sigma\left( \mathcal{E}^{(x,m)}_{y,+} : y \geq x \right)$, and further approximate $\Delta_y^{(x,m)}$ by its conditional mean with respect to $\mathcal{G}_{y-1}^{(x,m)}$,
	\begin{equation}\label{eq: conditional mean}
		\rho_{y}^{(x,m)}= \mathbb{E}\left[\Delta_y^{(x,m)} | \mathcal{G}_{y-1}^{(x,m)}\right].
	\end{equation}
	Then \eqref{eq: control of acc drift + } follows from the following two propositions:
	\begin{proposition}\label{lm: approximation of means of local drift}
		Let $p\in (0,\frac{1}{2}]$. Then, for any $t>0$ and any $\epsilon >0$
		\begin{equation}\label{eq: control of expected local drift}
			\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\sum_{y> X_k} \left( \rho_{y}^{(x,m)} - \gamma  \right)   }\cdot\mathbb{1}_{\{X_k\geq 0\}} > \epsilon \sqrt{n}  \right) =0. 
		\end{equation}
	\end{proposition}
	and
	\begin{proposition}\label{lm: approx local drift by conditional means}
		Let $p\in (0,\frac{1}{2}]$. Then, for any $t>0$ and any $\epsilon >0$
		\begin{equation}\label{eq: control of martingale difference for local drift}
			\lim_{n \to \infty }\mathbb{P}\left(\sup_{k\leq nt} \abs{\sum_{y> X_k} \left(\Delta_{y}^{(x,m)}- \rho_{y}^{(x,m)} \right)   } \cdot\mathbb{1}_{\{X_k\geq 0\}} > \epsilon \sqrt{n}  \right) =0. 
		\end{equation}
	\end{proposition}
	To prove both Propositions \ref{lm: approximation of means of local drift} and \ref{lm: approx local drift by conditional means}, we will introduce auxiliary processes associated to the SIRW $(X_n)_{n\geq 0}$: the generalized P\'{o}lya Urn process, and branching-like processes. Both processes are natural projections of $(X_n)_{n\geq 0}$ on certain space-time points, and they aid our approximations of $\Delta_{y}^{(x,m)}$ on certain good events. The good events in the proof of Proposition \ref{lm: approximation of means of local drift} are easier because events like Lemma \ref{lm: number of rarely visit sites} below will almost do the job, and estimates of their probabilities are essentially known from \cite{KMP22}. However, the good events for Proposition \ref{lm: approx local drift by conditional means} requires a new construction, and estimating the error requires a new proof, which is the major novelty of this article. We will postpone the proofs of Propositions \ref{lm: approximation of means of local drift} and \ref{lm: approx local drift by conditional means} and constructions of good events to section \ref{sec: approximations} after introducing the generalized P\'{o}lya Urn process, and branching-like processes in section \ref{sec: generalized Polya Urn, BLP}.
	
	\TBD With some slight efforts, we extend \eqref{eq: control of acc drift + } for $\Gamma_k^+$ to $\Gamma_k^-$, and obtain the full Proposition \ref{lm: control of acc drift}.
	
	
	\textbf{Step 3: Tightness.} \TBD This follows from (\cite{KMP22}, Proposition~2.1).
	
	\textbf{Step 4: Convergence to BMPE.} \TBD The proof follows word by word.
	
\section{Generalized P\'{o}lya Urn, Branching-Like Processes}\label{sec: generalized Polya Urn, BLP}

	In this section, we describe two auxiliary processes, generalized P\'{o}lya urn processes and branching-like processes, and recall some of their properties needed in the proofs of Propositions \ref{lm: control of martingale}, \ref{lm: approximation of means of local drift}, and \ref{lm: approx local drift by conditional means}. Both processes can be obtained from the SIRW $(X_n)_{n\geq 0}$ at stopping times. We start with the generaized P\'{o}lya urn processes. 

\subsection{Generalized P\'{o}lya  Urn}

	Given a (recurrent) random walk $(X_n)_{n\geq 0}$, and a fixed site $y\in \mathbb{Z}$, we can obtain a Markov process by considering only the up-crossings and down-crossings of $X_n$ from site $y$. More precisely, let $(\lambda_{y,i})_{i\geq 0}$ be the stopping times when $X_n$ \edt{visits site $y$ for the $\left( i+1 \right) $-th time:}
	\[
	 \lambda_{y,0} :=\inf\{ k\geq 0: X_k = y \} , \quad \lambda_{y,i+1} := \inf\{ k> \lambda_{y, i}: X_k = y \}.
	\] 
	
	\edt{which is consistent with the notation in point 3 of subsection 1.4. }
	We define the \textit{generalized P\'olya urn process} at site $y$ to be the tuples 
	\[
	\left(\mathcal{B}^{(y)}_{i},\mathcal{R}^{(y)}_{i} \right)_{i\ge 0}
	:=\left(\mathcal{E}^{\lambda_{y,i}}_{y,-}, \mathcal{E}^{\lambda_{y,i}}_{y,+}\right)_{i\geq 0} 
	\equiv  \left(\mathcal{E}^{(y,i)}_{y,-}, \mathcal{E}^{(y,i)}_{y,+}\right)_{i\geq 0}
	\] 
	which is a Markov process with an initial value $(0,0)$. \comment{We can use $k$ only in the context of $X_k$.} Intuitively, $\left(\mathcal{B}_{y,i},\mathcal{R}_{y,i} \right)$ can be thought of as the state a (generalized) P\'lya's urn, after the $i$-th draw made from the urn. This is the reason that we define $\lambda_{y, 0}$ to be the first time the walk reaches $y$ : this is right before the first draw be made from the urn. 

	The undirected edge local times of $\{y,y-1\}$ and $\{y,y+1\}$ at stopping times $\lambda_{y, i}$, denoted $l^-(y,i)$ and $l^+(y,i)$, are always related to the urn processes by
	\begin{align*}
		l^-(y,i) &= l^-(y,0) + 2 \mathcal{B}_{y,i} \\
		l^+(y,i) &= l^+(y,0) + 2 \mathcal{R}_{y, i}
	.\end{align*}

	The initial values of $l^-$ and $l^+$ correspond to undirected edge local times before the first excursion from $y $:
	\[
		\left(l^-(y,0),l^+(y,0)\right) =  \begin{cases}	
		(1, 0) &,  \text{ if }  y>0 \\
		(0, 1) &,  \text{ if }  y<0 \\  
		(0, 0) &,  \text{ if }  y=0 \\ 
	\end{cases}
\] 
	Let $b(y,i)$ and $r(y,i)$ denote the weight of corresponding edges:
	\begin{align*}
		b(y,i) &:= w(l^-(y,i)) \\
		r(y,i) &:= w(l^+(y,i))
	.\end{align*}
	Now the transition probabilities
	for the generalized P\'{o}lya urn process at a fixed site $y$ are given by
	\begin{align*}\label{eq: transition prob for GPU}
		\mathbb{P} \left( \left(\mathcal{B}_{i+1},\mathcal{R}_{i+1}\right)=   \left(\mathcal{B}_{i}+1,\mathcal{R}_{i}\right) \right)     &= \frac{b(i)}{b(i)+r(i)}, \mbox{ and}  \\
		\mathbb{P} \left( \left(\mathcal{B}_{i+1},\mathcal{R}_{i+1}\right)=   \left(\mathcal{B}_{i},\mathcal{R}_{i}+1\right) \right)     &= \frac{r(i)}{b(i)+r(i)},
	\end{align*} 


	where we drop the subscript $y$ for simplicity of notation. We will continue to do so when we talk about a fixed site of $y$ and when there's no confusion.

	For a generalized P\'{o}lya urn process $(\mathcal{B}_i,\mathcal{R}_i )_{i\geq 0}$ associated to the site $y$, it is convenient to consider the event times of left/right jumps $\tau^\mathcal{B}_k$ and $ \tau^\mathcal{R}_k $,	
	\edt{$$ \tau^\mathcal{B}_k = \inf\{ i\geq 0: \mathcal{B}_{i} =k   \}  \mbox{, and } \tau^\mathcal{R}_k = \inf\{ i\geq 0: \mathcal{R}_{i} =k   \} ,
	$$}
	\comment{Would be simpler to define $\tau^\cdot_k$ for general process?}
	and the signed difference $\mathcal{D}_{i} $ for any $i\geq 0$
	\begin{equation}\label{eq:signed difference}
		\mathcal{D}_i  =\mathcal{R}_i -\mathcal{B}_i.  
	\end{equation}
	Also, for every integer $i\geq 0$, we denote by $\mathcal{F}^{\mathcal{B},\mathcal{R}}_i$ (or $\mathcal{F}^{\mathcal{B},\mathcal{R}}_{i,y}$) the sigma algebra generated by  
	\[
	\mathcal{F}^{\mathcal{B},\mathcal{R}}_i = \sigma\left(\left(\mathcal{B}_j,\mathcal{R}_j \right): j\leq i \right)
	.\]  
	
	\TBD With the generalized P\'{o}lya urn process $(\mathcal{B}_i,\mathcal{R}_i )_{i\ge 0}$ associated to the site $y$, we can study $\Delta_{y}^{(x,m)}$ and its approximation $\rho_{y}^{(x,m)}$ defined in \eqref{eq: accumulated local drift} and \eqref{eq: conditional mean}. For $y>x $, at time $\lambda_{x,m}$, the local time at site $y$ is $L(y,\lambda_{x,m})$, and the last jump from site $y$ is a left jump. Then for any integers $k\geq 1$ and $k' \geq 0$, the event 

		$$\left\{ \mathcal{E}^{(x,m)}_{y-1,+} =k, \mathcal{E}^{(x,m)}_{y,+} = k'\right\} = \left\{\mathcal{E}^{(x,m)}_{y,-} =k,  L(y,\lambda_{x,m}) = k+k' \right\} = \{ \tau^\mathcal{B}_{k,y} = k+k' \},$$ on which the (random) quantity $\Delta_{y}^{(x,m)}$ equals

		\comment{How about writing $\tau^{\mathcal{B}, y}_k$ in place of $\tau^{\mathcal{B}}_{k, y}$?}
		 
		\[
		\Delta_{y}^{(x,m)} =\sum_{j=0}^{ L(y,\lambda_{x,m})-1} \mathbb{E}\left[ \mathcal{D}_{j+1} -\mathcal{D}_{j}  \vert \mathcal{F}^{\mathcal{B},\mathcal{R}}_{j} \right] = \sum_{j=0}^{\tau^B_{k,y}-1} \mathbb{E}\left[ \mathcal{D}_{j+1} -\mathcal{D}_{j}  \vert \mathcal{F}^{\mathcal{B},\mathcal{R}}_{j} \right]
		.\] 

		Summing over the terms between two consecutive stopping times $\tau^{B}_{l,y} $ and $\tau^{B}_{l+1,y} $, for any $0\leq l \leq k -1$,  we get a sum depending only on $\tau^{B}_{l,y} $, $\tau^{B}_{l+1,y} $, and 
		\begin{align} \label{eq: conditional increment}
		 	\sum_{j=\tau^{B}_{l,y}}^{\tau^B_{l+1,y}-1} \mathbb{E}\left[ \mathcal{D}_{j+1} - \mathcal{D}_{j}  \vert \mathcal{F}^{\mathcal{B},\mathcal{R}}_{j} \right] =&
		 	 \sum_{j=0}^{\tau^B_{l+1,y}-\tau^{B}_{l,y}-1} \frac{ r(\tau^{B}_{l,y}-l + j) - b(l)  }{ r(\tau^{B}_{l,y}-l + j) + b(l)  } 
		 	 =:  D(\tau^{B}_{l,y},\tau^{B}_{l+1,y} ),
		\end{align}   
		where $(b(k),r(k))_{k\geq 0}$ are the general weights associated to $y$ from \edt{\eqref{eq: generalized weights}}.
		Therefore,  $\Delta_{y}^{(x,m)}$ is a sum of $\mathcal{E}^{(x,m)}_{y-1,+} $ increments which depend only on $ \left(\tau^{B}_{l+1,y} - \tau^{B}_{l+1,y}: 0\leq l\leq   \mathcal{E}^{(x,m)}_{y-1,+}-1 \right) $
				\begin{equation} \label{eq: cummulated drift at a site}
					\Delta_{y}^{(x,m)} = \sum_{l=0 }^{ \mathcal{E}^{(x,m)}_{y-1,+} -1  } D(\tau^{B}_{l,y},\tau^{B}_{l+1,y} ).
				\end{equation}			
		Notice that from \eqref{eq: conditional increment}, $\abs{  D(\tau^{B}_{l,y},\tau^{B}_{l+1,y} )} \leq  \tau^{B}_{l+1,y}-\tau^{B}_{l,y}$ is stochastically dominated by a geometric random variable with mean independent of $l$. 
		Then, on the event that $ \mathcal{E}^{(x,m)}_{y-1,+} = k $, $ \rho_{y}^{(x,m)} $ is
		\begin{equation}\label{eq: conditional mean in GPU represenetation}
			\rho_{y}^{(x,m)} = \mathbb{E}\left[\Delta_{y}^{(x,m)} \vert \mathcal{G}_{y-1}^{(x,m)}\right] = \sum_{l=0 }^{ L -1  } \mathbb{E}\left[ D(\tau^{B}_{l,y},\tau^{B}_{l+1,y} ) \right] = \mathbb{E}\left[ \mathcal{D}_{\tau^{B}_{L,y}} \right],
		\end{equation} which is $\mathcal{G}_{y-1}^{(x,m)}$- measurable since $\mathcal{E}^{(x,m)}_{y-1,+} $ is $\mathcal{G}_{y-1}^{(x,m)}$- measurable. 
		Expressions like \eqref{eq: cummulated drift at a site} and \eqref{eq: conditional mean in GPU represenetation} help us simplify the analysis of $\Delta_{y}^{(x,m)}$ and $\rho_{y}^{(x,m)}$, as will be shown section \ref{sec: approximations}. To estimate events like $ L(y,\lambda_{x,m}) = k+k'$ and $\mathcal{E}^{(x,m)}_{y-1,+} = k $, the branching-like processes play a key role. 
		
		
		\subsection{Branching-Like Processes}
		Unlike the generalized P\'{o}lya urn process $(\mathcal{B}_k,\mathcal{R}_k )_k$ which is a Markov process derived from $X_n$ associated to a single site $y$ in $\mathbb{Z}$, the branching-like processes is a Markov process spatially, and it describes the local times of directed edges of $(X_n)_{n\geq 0}$ at a fixed stopping time. More precisely, for an SIRW $(X_n)_{n\geq 0}$ with weight $w(.)$, at any fixed time $n \geq 0$, assuming that $X_n = x \geq 0 $, the local times $\tilde{\zeta}= \left(\mathcal{E}^{n}_{x+k,+} \right)_{k\geq 0}$, and ${\zeta}= \left(\mathcal{E}^{n}_{x-k,-} \right)_{k\leq 0}$ are two Markov processes on $\mathbb{N}\cup\{0\}$, whose transition probabilities are related to the generalized weights in \eqref{eq: generalized weights}. The transition probabilities can be derived from a correspondence from one dimensional random walk and a branching process. \TBD Formally, we can project a random walk on $\mathbb{Z}$ (up to any finite time) on a tree by viewing each $X_n= k$ as an agent of the $k$-th generation. Each right move from $X_n=k$ to $X_{n+1}=k+1$ gives a birth to a descendant in the $k+1$-th generation, and each left move traces the ancestor of $X_n=k$ in the $k-1$-th generation. It is possible that an agent $A$ corresponding to $X_n=k$ in the $k$-th generation has more than one $n$ with $X_n=k$, and it is visited exactly $L+1$ times if it has exactly $L$ descendants in the $k+1$-th generation and $X_T $ is not in the sub-tree with the root $A$. 
		Then, since $X_0=0$ and $X_n =x \geq 0$, the difference $\mathcal{E}^n_{y,+} -\mathcal{E}^n_{y+1,-} $ depends on the relative position of $y$ with respect to $x$ and $0$ 
		\begin{equation}\label{eq: edge values}
			\mathcal{E}^n_{y,+} =\begin{cases}
				\mathcal{E}^n_{y+1,-} &\mbox{, for all $y\geq x$}\\
				\mathcal{E}^n_{y+1,-} +1 &,\mbox{ for all $0 \leq y\leq x$}
				\\
				\mathcal{E}^n_{y+1,-} &,\mbox{ for all $ y< 0 $}
			\end{cases}
		\end{equation}
		The transition probabilities for $\bar{\zeta}$ is more direct because upcrossings in $X_n$ corresponds to giving births to new descendants in the branching process, while $\zeta$ is slightly more complicated and $\zeta$ has a transition probabilities depending on values of $y,0,x$: 
		\begin{enumerate}
			\item $\tilde{\zeta}$ is a homogeneous Markov chain defined on  $\mathbb{N}\cup\{0\}$ with $i,j\geq 0$
			\begin{equation}\label{eq: transition prob on positive}
				\mathbb{P}\left(\tilde{\zeta}_{k+1}=j \vert \tilde{\zeta}_k =i  \right) = 
				\mathbb{P}\left( \mathcal{R}_{\tau_i^B} = j \right), 
			\end{equation} where $(\mathcal{B}_k,\mathcal{R}_k )_k$ has generalized weights $(b(k), r(k))$ corresponds to the case when $y>0$.
			$$
			(b(k), r(k)) = (w(2k+1), w(2k)).
			$$
			
			\item  $\zeta$ is an inhomogeneous Markov chain defined on  $\mathbb{N}\cup\{0\}$ whose transition probabilities depends on the values of $x-k<0$, $x-k = 0$ , and $x-k >0$, for $i,j\geq 0$
			\TBD(needs to double check the formula)
			\begin{equation}\label{eq: transition prob on positive }
				\mathbb{P}\left(\tilde{\zeta}_{k+1}=j \vert \tilde{\zeta}_k =i  \right) = 
				\begin{cases}
					\mathbb{P}\left( \mathcal{B}_{\tau_{i+1}^R} = j \right) ,& \mbox{ if $0 \leq k <  x-1$ }
					\\
					\mathbb{P}\left( \mathcal{B}_{\tau_{i+1}^R} = j \right) ,& \mbox{ if  $k =  x-1$ }
					\\
					\mathbb{P}\left( \mathcal{R}_{\tau_i^B} = j \right) ,& \mbox{ if $k \geq x$ }
				\end{cases}
			\end{equation} where the generalized weights $(b(k), r(k))$ corresponds to the case when $y>0$, $y=0$ and $y<0$ from \eqref{eq: generalized weights}
			$$
			(b(k), r(k)) = \begin{cases}
				(w(2k+1), w(2k)) &,  \text{ if }  y>0 \\
				(w(2k), w(2k+1)) &,  \text{ if }  y<0 \\  
				(w(2k), w(2k)) &,  \text{ if }  y=0 \\ 
			\end{cases}.
			$$	 
		\end{enumerate}
		In the case when $X_n = z\leq 0$, we can exchange the roles of $\zeta$ and $\bar{\zeta}$ and consider the local times of downcrossings/upcrossings away from site $x\leq 0$,  $\bar{\zeta'}= (\mathcal{D}^{n}_{x-k} )_{k\leq 0}$ and $\zeta'= (\mathcal{E}^{n}_{x+k} )_{k\geq 0}$. Due to symmetry, the new processes $\bar{\zeta'}$ and $\zeta'$ for $x\leq 0$ has the same distributions as $\zeta,$ and $\bar{\zeta}$ for $-x\geq0$.
		
		The construction of branching-like processes enables us to consider a generic time $k\leq nt$ and study the local times at a time $k$ from the Markov processes $\zeta$ and $\bar{\zeta}$. An advantage is that a typical event (\TBD{see equations to be defined in section \ref{sec: approximations}}) on a collection of spatial points will be also a typical event on a 'typical' single site. Then expressions like \eqref{eq: conditional mean in GPU represenetation} reduces the problem to a problem involving generalized P\'{o}lya urn process associated to a single site. The difficulty is then transferred to constructing typical events that can be estimated. For example, Lemma \ref{lm: number of rarely visit sites} below describes a typical event, and it reduces the proof of proposition \ref{lm: approximation of means of local drift} to \eqref{eq: convergence of conditional expectation} below. In the following subsection, we recall some properties of generalized P\'{o}lya urn process and branching-like processes.
		
		\subsection{Preliminary Results}
		To facilitate our arguments in section \ref{sec: approximations}, we list four results from \cite{KMP22,T96}, whose proofs \textcolor{red}{we omit at this moment.}
		
		The first result is a concentration inequality for $\mathcal{D}_i$ in a generalized P\'{o}lya urn process. This lemma is a major tool in estimating the probabilities of good events.
		\begin{lemma}(Lemma 4.1 \cite{KMP22})\label{lm: concentration inequality}
			Let weights $r(i) = w(2i)$, $b(i)= w(2i+1) $ for all $i\geq 0$. Then there exists constants $C,c>0$ such that for $k, m \in \mathbb{N}$,
			$$
			P\left(  \abs{ \mathcal{D}_{\tau_k^B}   } \geq m \right) \leq C e^{\frac{-cm^2}{m \vee k}}.
			$$
		\end{lemma} 
		Lemma \ref{lm: concentration inequality} remains valid for the generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})_k$ associated to sites $y<0$ and $y=0$. For these two cases, the sequence of weights $(r(i),b(i))$ are slightly different, see \eqref{eq: generalized weights}. When $y<0$, $r(i) = w(2i+1)$, $b(i)= w(2i) $; when $y=0$, $r(i) = b(i)=w(2i)$.
		
		The second result is an identity for a generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})_k$. For any $k\geq 0$ denote by $\mu(k)= \tau^B_k - k$ the number of red balls extracted before the $k$-th blue ball. 
		\begin{lemma}(Lemma 1, \cite{T96}) \label{lm: Toth's Identity}
			For any $m\in \mathbb{N}$ and $\lambda < \min\{ b(j): 0\leq j\leq m-1 \}$, we have the following identity,
			$$  \mathbb{E}\left[  \prod_{j=0}^{ \mu(m)-1 } \left(1+ \frac{\lambda}{r(j)}   \right) \right] =   \prod_{j=0}^{ m-1 } \left(1- \frac{\lambda}{b(j)}   \right)^{-1}.   $$ 
			In particular, 
			\begin{equation}\label{eq: Toth's Identity 1}
				\mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}   \right] =   \sum_{j=0}^{ m-1 } \frac{1}{b(j)}.
			\end{equation}	
		\end{lemma}
		\eqref{eq: Toth's Identity 1} is a direct consequence of the first identity. And the first identity can be proved via (exponential) martingales associated to the generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})$, 
		$$M_k(\lambda) = \prod_{i=0}^{ \mathcal{B}_{k}-1 } \left(1-\frac{\lambda}{b(i)}\right) \prod_{j=0}^{\mathcal{R}_{k}-1 } \left(1+\frac{\lambda}{r(j)}\right). $$
		
		The third result is about the diffusion approximations of the branching-like processes, and it follows from the Proposition A.3 in \cite{KMP22}. Its proof follows arguments from Toth \cite{T96}. A consequence of this result is the process level tightness of extrema, Proposition 2.1 \cite{KMP22}. 
		
		\begin{lemma}(Proposition A.3 \cite{KMP22})\label{lm: diffusion approximation of blp}
			For $n\geq 1$, let $\zeta^{(n)}=(\zeta^{(n)}_k)_{k\geq 0 }  $ be the BLP with initial value $\zeta^{(n)}_0 = \lfloor yn \rfloor$ for some $y \geq 0$, and let $\mathcal{Z}_n(t) = \frac{\zeta^{(n)}_{\lfloor nt \rfloor}}{n}$ for $n\geq 1$ and $t\geq 0$. Then we have that 
			$$
			\mathcal{Z}_n(.) \Longrightarrow Z^{(2-2\gamma)}(.)
			$$ as $n$ goes to infinity on $D([0,\infty)),$ where $Z^{(2-2\gamma)}(.)$ is the squared Bessel processes of dimension $2-2\gamma$.
		\end{lemma}

		
		The last result is a result from the branching-like processes. It gives a control of the number of sites with "small" local times:
		\begin{lemma}(Lemma 2.2 \cite{KMP22})\label{lm: number of rarely visit sites}
			Let $\alpha =0$, and $\gamma_+ = \gamma \vee 0$. Then for any $M>0$, and any $b>\frac{\gamma_+}{2}$ we have
			$$
			\lim_{n\to\infty} P\left(\sup_{k\leq nt}  \sum_{x\in [I^X_{k-1}, S^X_{k-1}]} \mathbb{1}_{\{ L(x,k-1) \leq M \}} \geq 4n^b \right) = 0.
			$$
			
		\end{lemma}	
		Lemma \ref{lm: number of rarely visit sites} is a technical result, and its proof involves the analysis of BLPs and the concentration inequality in Lemma \ref{lm: concentration inequality} for the generalized P\'{o}lya urn process. The statement of Lemma \ref{lm: number of rarely visit sites} remains in force if we replace the range $[I_{k-1}, M_{k-1}]$ by $[X_k,M_k]$ (or $[I_{k-1},X_k]$ respectively), and replace the local times $L(x,k-1)$ by the numbers of up-crossings $\mathcal{E}^{k}_{x,+}$ (or $\mathcal{E}^{k}_{x,-}$ respectively). In fact, these two extended results are partial steps in the proof of Lemma 2.2 in \cite{KMP22}.   
		
		
		\section{Approximations of Local Drifts}\label{sec: approximations}
		In this section, we will prove the technical propositions in the proof of Theorem \ref{thm: main}. \TBD
		
		
		\subsection{Convergence of conditional Expectation}
		In view of the generalized P\'{o}lya urn process (associated to a site $y> x$), on the event that $ L = \mathcal{E}^{(x,m)}_{y-1}$, we have \eqref{eq: conditional mean in GPU represenetation} 
		$$\rho^{(x,m)}_y = E[\mathcal{D}_{\tau_L^B}].$$ 
		On one hand, $M_{nt} \leq K\sqrt{n} $ for some $K>0$ with a high probability; on the other hand, Lemma \ref{lm: number of rarely visit sites} says that, up to $n^b$ sites, (where $\frac{\gamma \vee 0}{2}<b<\frac{1}{2}$,) every site $y$ between $X_k=x$ and $\mathcal{M}^{(x,m)} =S_{k}^X$ has $ \mathcal{E}^{(x,m)}_{y-1} \geq M  $ with a high probability. To show Proposition \ref{lm: approximation of means of local drift}, it suffices to show 
		\begin{equation}\label{eq: convergence of conditional expectation}
			\lim_{M\to\infty} E[\mathcal{D}_{\tau_M^B}] = \gamma , 
		\end{equation} for positive sites. A symmetric argument allows us to get the factor $sgn(y)$ for sites $y<0$ and $y=0$.
		
		\begin{lemma} \label{lm: convergence of mean of discrepancies}
			For the generalized P\'{o}lya urn process $(\mathcal{B}_{k},\mathcal{R}_{k})$ with weights $r(i)= w(2i)$, $b(i) = w(2i+1)$ for all $i\geq 0$, we have that
			$$
			\lim_{M\to\infty} E[\mathcal{D}_{\tau_M^B}] = \gamma. 
			$$
		\end{lemma} 
		\begin{proof} 
			We start from \eqref{eq: gamma} and identity \eqref{eq: Toth's Identity 1}. For any $m \geq 10$,
			\begin{align}
				V_1(m) - U_1(m) =& \sum_{i=0}^{m-1} \frac{1}{w(2i+1)} -\sum_{i=0}^{m-1} \frac{1}{w(2i)} 
				\notag \\
				=& \sum_{i=0}^{m-1} \frac{1}{b(i)} -\sum_{i=0}^{m-1} \frac{1}{r(i)} 
				\notag \\
				=& 	\mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}   \right] - \sum_{i=0}^{m-1} \frac{1}{r(i)} = \mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}    - \sum_{i=0}^{m-1} \frac{1}{r(i)}\right]. \label{eq: difference}
			\end{align}
			From \eqref{eq: asymptotics of w}, we have that $0< \inf \frac{1}{r(j)} \leq \sup \frac{1}{r(j)} <\infty $, then $\mathbb{E}\left[\mu(m)\right]$ is bounded by
			$$\mathbb{E}\left[ \mu(m) \right] = \mathbb{E}\left[ \mu(m)\mathbb{1}_{\mu(m)\geq 1} \right] \leq  \frac{1}{\inf 1/w(j) }\mathbb{E}\left[  \sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)}   \right] <\infty, $$ 
			so $ \mathbb{E}\left[ \mu(m) -m\right]  $ is bounded.
			The difference in \eqref{eq: difference} can be written as
			\begin{align} 
				\sum_{j=0}^{ \mu(m)-1 } \frac{1}{r(j)} - \sum_{i=0}^{m-1} \frac{1}{r(i)} =& \sum_{j=m}^{\mu(m)-1} \left(\frac{1}{r(j)} -\frac{1}{r(m)} \right) \cdot\mathbb{1}_{\{\mu(m)\geq m\}} 
				\label{eq: 1st term}
				\\	
				& - \sum_{j=\mu(m)}^{m-1} \left(\frac{1}{r(j)} -\frac{1}{r(m)} \right) \mathbb{1}_{\{\mu(m)< m\}} 
				\label{eq: 2nd term}
				\\
				& + \frac{\mu(m)-m}{ r(m) }. \label{eq: major term}
			\end{align} 
			Since $\mu(m)-m =  \mathcal{D}_{\tau^B_m}$, the last term \eqref{eq: major term} is exactly $\frac{1}{r(m)} \mathcal{D}_{\tau^B_m}$, which has an expectation $\frac{1}{r(m)} \mathbb{E}\left[\mathcal{D}_{\tau^B_m}\right].$ Both \eqref{eq: 1st term} and \eqref{eq: 2nd term} have finite expectations, which vanish as $m$ goes to infinity:
			
			Indeed, let $A> \frac{2}{c} \vee 1$, where $c$ is from Lemma \ref{lm: concentration inequality}. \eqref{eq: 1st term} is bounded by
			\begin{align}
				\sum_{j=m}^{\infty} \left(\abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \cdot \mathbb{1}_{\{\mu(m)\geq j \}}\right) & \leq  \sum_{0\leq j-m \leq A \sqrt{m}\log m } \left(\abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \cdot \mathbb{1}_{\{\mu(m)\geq j \}}\right) 
				\notag
				\\
				& +  \sum_{j-m > A\sqrt{m}\log m } \left(\abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \cdot \mathbb{1}_{\{\mu(m)\geq j \}}\right)
				\notag
				\\
				&\leq  \sum_{0\leq j-m \leq A\sqrt{m}\log m } \abs{\frac{1}{r(j)} -\frac{1}{r(m)} }
				\label{low difference}
				\\
				& + 2\left(\sup_j \frac{1}{w(j)}\right) \cdot \sum_{j\geq m + A\sqrt{m}\log m } \mathbb{1}_{\{ \mu(m) > j \}}
				\label{large difference}
			\end{align}
			In view of \eqref{eq: asymptotics of w}, there is a constant $C'>0$ such that for any $m>100 $ and any $j$ with $\abs{j-m}\leq A \sqrt m \log m $, 
			$$ \abs{\frac{1}{r(j)} -\frac{1}{r(m)} } \leq C' A m^{-p-\frac{1}{2}} \log m, $$
			which implies that \eqref{low difference} is bounded by
			$$
			C' A^2 m^{-p} (\log m)^2.
			$$ On the other hand, Lemma \ref{lm: concentration inequality} implies that the expectation of \eqref{large difference} is bounded by
			\begin{align*}
				& 2\left(\sup_j \frac{1}{w(j)}\right) \sum_{j-m \geq A \sqrt m \log m  } P( \mathcal{D}_{\tau^B_m} \geq j-m )  
				\notag 
				\\
				\leq& 2\left(\sup_j \frac{1}{w(j)}\right) \sum_{l \geq A \sqrt m \log m } C \exp\left( - \frac{c  \cdot l^2}{l \vee m}   \right)
				\notag\\
				\leq& C'' \left( \exp (- cA^2 \cdot \log m ) + \exp(-cA \cdot \log m) \right), 
			\end{align*} for some $C''$ independent of $m$. Therefore, the expectation of \eqref{eq: 1st term} is bounded by
			\begin{equation}\label{boound}
				C' A^2 m^{-p} \log m + C''  \left( m ^{-cA^2} +  m^{-cA} \right). 
			\end{equation}
			One can treat \eqref{eq: 2nd term} similarly. 
			
			With our choice of $A >\frac{2}{c} \vee 1$, \eqref{eq: difference}, \eqref{eq: 1st term}, \eqref{eq: 2nd term}, \eqref{eq: major term}, and \eqref{boound}, we get that
			$$ \abs{ V_1(m)- U_1(m) -\frac{1}{r(m)}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] }
			\leq 2C' A^2 m^{-p} \log m + 2C''  \left( m ^{-cA^2} +  m^{-cA} \right), 
			$$ which converges to $0$ as $m$ goes to infinity. We conclude that
			$$
			\lim_{m\to\infty}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] = \gamma, 
			$$ from $\lim_{m\to\infty}\frac{1}{r(m)} =1$ and $ \lim_{m\to \infty} \left(V_1(m)-U_1(m) \right) = \gamma$.
		\end{proof}
		
		For the generalized P\'{o}lya urn process associated to a site $y<0$, we have $r(i) = w(2i+1)$, $b(i) =w(2i)$. The right hand side of \eqref{eq: difference} is the same as $U_1(m)-V_1(m)$, which converges to $-\gamma$ as $m$ goes to infinity. Then we get that  $$\lim_{m\to\infty}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] = -\gamma.$$
		Similarly, for $y=0$, the associated generalized P\'{o}lya urn process has 
		$$\lim_{m\to\infty}\mathbb{E}\left[ \mathcal{D}_{\tau^B_m} \right] = 0.$$
		
		\TBD \textcolor{red}{We will need to define $\rho$ for negative sites.} We extend the definition of $\rho^{(x,m)}_y$ for sites $y< x$ by symmetry, 
		$$\rho^{(x,m)}_y := \mathbb{E}\left[  \Delta^{(x,m)}_y   \left\vert  \sigma\left( D^{(x,m)}_z:  y<z\leq  x  \right. \right) \right].   $$ In terms of the generalized P\'{o}lya urn process associated to the site $y$,
		\begin{equation} \label{eq: extended definition}
			\rho^{(x,m)}_y = \mathbb{E}\left[\mathcal{D}_{\tau_L^R}\right], 
		\end{equation} where $L = \mathcal{E}^{(x,m)}_{y+1,-} = \mathcal{E}^{(x,m)}_{y,+}.$ With an argument similar to the proof of Lemma \ref{lm: convergence of mean of discrepancies}, we get that 
		\begin{equation}\label{eq: mean of discrepancies for left sites}
			\lim_{L\to \infty} \mathbb{E}\left[\mathcal{D}_{\tau_L^R}\right] =  sgn(y) \cdot \gamma = \lim_{L\to \infty} \mathbb{E}\left[\mathcal{D}_{\tau_L^B}\right].
		\end{equation}
		
		Now we show Proposition \ref{lm: approximation of means of local drift} and a slightly stronger result. 
		\begin{lemma}
			Let $w(.)$ be a positive monotone function on $\mathbb{N}_0$ satisfying \eqref{eq: asymptotics of w}. Then for any $0<p<1$, any $\epsilon>0$,
			$$
			\lim_{n\to\infty} P\left( \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,S_{k}^X]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}     \right) =0.
			$$
			Furthermore,
		$$
	\lim_{n\to\infty} P\left( \sup_{k\leq n t}  \abs{  	\sum_{y\in [I_k^{X} ,S_{k}^X]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}     \right) =0.
	$$
\end{lemma}
\begin{proof} There are only three types of weight sequences for the generalized P\'{o}lya urn processes, see \eqref{eq: generalized weights}. Therefore, from Lemma \ref{lm: convergence of mean of discrepancies}, and \eqref{eq: mean of discrepancies for left sites}, there is a decreasing function $C(.)$ on $\mathbb{N}_0$ with $\lim_{L\to \infty}C(L) =0$ such that for any $y \in \mathbb{Z}$,
	\begin{equation}\label{eq: uniform convergence}
		\abs{\mathbb{E}\left[ \mathcal{D}_{\tau_L^R} \right] - \gamma \cdot sgn(y)}, \abs{\mathbb{E}\left[ \mathcal{D}_{\tau_L^B} \right] - \gamma \cdot sgn(y)} \leq C(L).
	\end{equation} One such function is $C(l) = \sup \left\{  \abs{\mathbb{E}\left[ \mathcal{D}_{\tau_m^R} \right] - \gamma \cdot sgn(y)} + \abs{\mathbb{E}\left[ \mathcal{D}_{\tau_m^B} \right] - \gamma \cdot sgn(y)} : m\geq l \right\}.     $  
	
	
	Let $t>0$, and $b \in [\frac{\gamma \vee 0 }{2},\frac{1}{2})$.  For any $n,K,M>0$, we consider three types of events, 
	$$A_{n,K}:=\left\{ \min\{-I_{nt}, M_{nt}\} \geq K \sqrt{n}  \right\}$$
	$$B_{n,M}:= \left\{  \sup_{k\leq n t} \sum_{ y\in (X_{k-1}, M_{k-1}]}  \mathbb{1}_{\{ \mathcal{E}^{k-1}_{y-1,+} \leq M  \}} >n^b  \right\},  $$
	and 
	$$B'_{n,M}:=  \left\{  \sup_{k\leq n t} \sum_{ y\in [I_{k-1}, X_{k-1})}  \mathbb{1}_{\{ \mathcal{D}^{k-1}_{y+1} \leq M  \}} >n^b  \right\}.$$
Clearly, $A_{n,K}$ is decreasing in $K$, and $B_{n,M}, B'_{n,M}$ are increasing in $M$. We claim that for $n$ large, the event 
$$
F_{n,\epsilon}:= \left\{ \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,M_k]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}    \right \}$$ is contained in $A_{n,K} \cup B_{n,M} $ for some finite $K, M$ independent of $n$:   

	Indeed, depending on $(\mathcal{E}^{k-1}_{y-1,+} \leq M)$, terms  $\left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right)$ are bounded by $C(0)$ or $C(M)$. Therefore, the supremum is bounded by
	\begin{align*}
	 \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,M_k]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \leq &  
	 C(0) \cdot \sup_{k\leq n t} \left\{   	\sum_{y\in [X_{k}+1 ,M_k]} \mathbb{1}_{ \{ \mathcal{E}^{k-1}_{y-1,+} \leq M \} } \right\}
	 \notag
	 \\
	 +& C(M) \cdot \sup_{k\leq n t} \left\{   	\sum_{y\in [X_{k}+1 ,M_k]} \mathbb{1}_{ \{ \mathcal{E}^{k-1}_{y-1,+} \geq M \} } \right\},
\end{align*} which is bounded on $A^c_{n,K} \cap B^c_{n,M}$ by
\begin{equation}\label{eq: an upper bound on good set}
	C(0)n^b  + C(M) \left(K \sqrt{n} -n^b\right).
\end{equation} As $n$ goes to infinity, \eqref{eq: an upper bound on good set} is smaller than $\epsilon \sqrt{n}$ for any $K>0$ and any $M$ with $C(M) < \frac{\epsilon}{2K}$ . 
For such pairs of $(K,M)$, $A^c_{n,K} \cap B^c_{n,M} \subset F^c_{n,\epsilon}$ when $n$ is large,  and 
$$
\limsup_{n\to \infty} P(F_{n,\epsilon}) \leq \limsup_{n\to \infty}  P(A_{n,K}) +  \limsup_{n\to \infty}  P(B_{n,M}).
$$ In view of Lemma \ref{lm: number of rarely visit sites} and the explanation after it, the second term $$\limsup_{n\to \infty}  P(B_{n,M})=0.$$  The first term $\limsup_{n\to \infty}  P(A_{n,K}) $ vanishes as $K$ goes to infinity, which is a consequence of Proposition 2.1 \cite{KMP22}, or Corollary 1A \cite{T96}.
 
The proof of 
$$  
\lim_{n\to\infty} P\left( \sup_{k\leq n t}  \abs{  	\sum_{y\in [I_k ,M_k]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}     \right) =0
$$ 
follows a similar argument. In particular, if we replace the range from $[X_k+1, M_k]$ by $[I_k,M_k]$, the event 
$$
\tilde{F}_{n,\epsilon}:= \left\{ \sup_{k\leq n t}  \abs{  	\sum_{y\in [X_{k}+1 ,M_{k}]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right) } \geq  \epsilon \sqrt{n}    \right \}
$$ 
is contained in $A_{n,K} \cup B_{n,M} \cup  B'_{n,M},$ for any $K>0$, and $M$ with $C(M) < \frac{\epsilon}{4K}$.
\end{proof}

\eqref{eq: an upper bound on good set} can be used as a crude estimate for 	$\sum_{y\in [X_{k}+1 ,M_{k}]} \left( \rho^{(X_k,L(X_k,k))}_y -  \gamma \cdot sgn(y) \right)$   on the "good events" $A^c_{n,K}\cap B^c_{n,M}$.

\subsection{Approximation of Local Drifts by Conditional Means}
In this subsection, we prove Proposition \ref{lm: approx local drift by conditional means}. \textcolor{red}{\TBD. Its proof is composed of by an argument similar to that on page 20 of \cite{KP16}.}

By construction, the inner sum in \eqref{eq: control of martingale difference for local drift} is a martingale depending on the pair  $(x,m)$. To control the sum, we restrict on a good event where this martingale has bounded increments. 

Consider some site $x \neq 0$ and let $m > 0$. By symmetry we only consider the case $x >  0$. \TBD. (enrich the argument to include discussion for the case $y < x$.) 
For every integer $K>0$ and define the good event

\begin{align}
	G_{n,K,t} :=  \qquad
		\label{eqn:good-event-1}
		& \left\{\sup _{k \le \left\lfloor nt  \right\rfloor} |X_k| < K \sqrt{n} \right\} \cap \\
		\label{eqn:good-event-2}
		& \left\{\sup_{y \in \mathbb{Z}} L(y, \left\lfloor nt  \right\rfloor) < K \sqrt{n} \right\} \cap \\
		\label{eqn:good-event-3}
		& \bigcap_{y = - K \sqrt{n} }^{K \sqrt{n}} 
		\bigcap_{i = 1}^{K \sqrt{n} } \left\{\left| \tau_i^{\mathcal{B}} - 2 i \right| < \sqrt{ i } \log^2 n \right\}  \cap \\
		\label{eqn:good-event-4}
		& \bigcap_{y = - K \sqrt{n} }^{K \sqrt{n}} 
		\bigcap_{i = 1}^{K \sqrt{n} } \left\{\left| \tau_{i+1}^{\mathcal{B}} - \tau_i^{\mathcal{B}} \right| < \log^2 n \right\}  
.\end{align}

\begin{lemma}
	\label{lem:good-event}
	For any $t > 0$, The good event $G_{n,K,t}$ satisfies
	\[
		\lim_{K \to \infty } \limsup_{n \to \infty } 
		P(G_{n, K,t}) = 1
	.\] 
\end{lemma}


The next lemma gives a deterministic bound for $|\Delta_y^{(x,m)} - \rho_y^{(x,m)}|$ uniform in $y$ on the good event $G_{n,K,t}$, making the inner sum in \eqref{eq: control of martingale difference for local drift} a martingale with bounded variations.

\begin{lemma}\label{lm:lipchitz-bound-on-good-event}
	On $G_{K}^{(x,m)}$, when $p \in (0,\frac{1}{2})$, for all  $y \ge x$, we have
	\[
		\left| \Delta_y^{(x,m)} \right| \le C_K n^{-\frac{1}{2}p + \frac{1}{4}} \log^4 n
	.\] 
	When $p = \frac{1}{2}$, for all $y \ge x$, we have
\[
		\left| \Delta_y^{(x,m)} \right| \le C_K \log^5 n
	.\]
	As a corollary, those bounds also apply to $\left| \Delta_y^{(x,m)} - \rho_y^{(x,m)} \right| $, up to a fixed multiplicative constant.
\end{lemma}


\begin{proof}[Proof of Proposition~\ref{lm: approx local drift by conditional means}]
Having Lemma~\ref{lm:lipchitz-bound-on-good-event}, we can apply Azuma's inequality to the sum in \eqref{eq: control of martingale difference for local drift} on $G_{n, K, t}$. In the case $p < \frac{1}{2}$ we get for all $\varepsilon>0$,

{\color{red} shall I write those as conditional probability on good event?}
\begin{align}
	P\left( \left| \sum_{y\ge X_k} (\Delta_y^{(x,m)} - \rho_y^{(x,m)})  \right| > \varepsilon \sqrt{n}  \right) \notag
	&\le \exp\left( - \frac{\varepsilon^2 n}{2 K \sqrt{n} \left( C_{K} n^{-\frac{1}{2}p + \frac{1}{4}} \log^2 n  \right)^2 } \right) + P\left(  G_{n, K, t}^c   \right) \notag \\
	&= \exp\left( - C_{K, \varepsilon} \, n^{p } \log^{-4} n \right) +
	P\left(  G_{n, K, t}^c   \right) 
   \label{eqn:azuma-drift-martingale}
.\end{align}
In the case $p = \frac{1}{2}$ the bound becomes
\begin{align}
	P\left( \left| \sum_{y \ge X_k} (\Delta_y^{(x,m)} - \rho_y^{(x,m)}) \right|  > \varepsilon \sqrt{n}  \right) \notag
	&\le  \exp\left( - C_{K, \varepsilon} \, \sqrt{n}  \log^{-5} n \right) + 
	P\left(  G_{n, K, t}^c   \right) 
.\end{align}
In both cases, the right hand side vanish when we first take $n $ to infinity, and then take $K$ to infinity. To bound $\sup_{k < nt} \left| \sum_{y \ge X_k} (\Delta_y^{(x,m)} - \rho_y^{(x,m)}) \right|$, we note that for every $k < nt$ there exists $(x,m)$ such that $x = X_k$ and $m = L(x,k)$. Thus, this amounts to bounding the supremum of $\left| \Delta_y^{(x,m)} - \rho_y^{(x,m)} \right| $ over all $(x,m)$ pairs. Moreover the Azuma-type bounds are uniform in $(x,m)$, so 
\begin{align*}
	& P\left( \sup _{k \le nt} \left| \sum_{y \ge X_k} \left(\Delta_y^{(x,m)} - \rho_y^{(x,m)}\right) \right|  > \varepsilon \sqrt{n}  \right) \\
	&\le P(G_{n, K, t}^c) + K^2 n \sup _{|x|, m \le  K \sqrt{n} }
	P\left( \left| \sum_{y \ge X_k} (\Delta_y^{(x,m)} - \rho_y^{(x,m)}) \right|  > \varepsilon \sqrt{n} \right) \\
	&\le P(G_{n, K, t}^c) + K^2 n \left( \exp\left( - C_{K, \varepsilon} \, n^{p } \log^{-4} n \right) + \exp\left( - C_{K, \varepsilon} \, \sqrt{n}  \log^{-5} n \right) \right) 
.\end{align*}
In view of Lemma~\ref{lem:good-event}, the last line vanishes as we first take $n$ to infinity and then take $K$ to infinity.
\end{proof}

\vspace{2em}

Next we justify the that the good event $G_{n, K, t}$ we defined is indeed typical.

\begin{proof}[Proof of Lemma~\ref{lem:good-event}]
	Fix $t>0$. We want to justify
	\[
		\lim_{K\to \infty } \limsup_{n \to \infty } G_{n, K, t} = 1
	.\] 
	To do so, we treat each term \eqref{eqn:good-event-1}-\eqref{eqn:good-event-4} in the definition of $G_{n, K, t}$ separately.

	From process-level tightness of $\left( \frac{X_{\left\lfloor nt  \right\rfloor}}{\sqrt{n} } \right)_{t \ge 0} $({\color{red} Reference Missing}) we know that probability of \eqref{eqn:good-event-1} goes to $1$ (uniformly in $n$) as $K $ goes to infinity. 

	The second event \eqref{eqn:good-event-2} provides uniform restriction to local time of all sites. Its probability is controlled by Lemma \TBD.

	The remaining two events \eqref{eqn:good-event-3} and \eqref{eqn:good-event-4} encode the asymptotic behavior of Polya's Urn processes at each site $y$. To establish the likelihood of \eqref{eqn:good-event-3}, note that the inner intersections over $i$ give rise to events that are i.i.d. over $y$. We may use concentration inequality for the Urn process (Lemma~\ref{lm: concentration inequality}) together with a supremum bound to control this event.
\begin{align*}
	1-P\left(\bigcap_{i = 1}^{K \sqrt{n} } \left\{\left| \tau_i^{\mathcal{B}} - 2 i \right| < \sqrt{ i } \log^2 n \right\}
\right) 
	&\le \sum_{y < \sqrt{n} }\sum_{i < K \sqrt{ n} } P\left( |\tau_i^{\mathcal{B}} - 2i| \ge \sqrt{i} \log^2 n \right) \\
	&\le CK \sqrt{n} \sum_{i < K \sqrt{ n} } \exp\left( - c \frac{i \log^4 n}{\sqrt{i}  \log^2 n \vee i} \right)  \\
	&\le CK \sqrt{n}  \sum_{i < K \sqrt{ n} }  
	\left( \exp\left( - c \sqrt{i}  \log^2 n \right)  + 
	\exp\left( - c \log^4 n \right) \right)
.\end{align*}
For fixed $K$, the last line goes to $0$ as $n$ goes to infinity. 

For \eqref{eqn:good-event-4}, we make a similar argument and note that, since the probability that the next ball drawn is blue is bounded below by some constant $q > 0$, $\tau_{i+1}^{\mathcal{B}} - \tau_{i}^{\mathcal{B}}$ is stochastically dominated by some geometric random variable $\text{Geo}(q)$. Hence for any specific $i$,

\[
	P\left(\left\{\left| \tau_{i+1}^{\mathcal{B}} - \tau_i^{\mathcal{B}} \right| \ge  \log^2 n \right\}\right) 
	\le C K^2 n \exp\left( - c \log^2 n \right) 
.\] 
This implies that the probability of event \eqref{eqn:good-event-4} goes to $1$ as $n$ goes to infinity, for any fixed $K$.

	We thus conclude that the probability of $G_{n, K, t}$ goes to $0$ as we first take $n$ to infinity and then take $K$ to infinity.
\end{proof}

\vspace{2em}

Finally, we verify the deterministic bound on martingale increments of \eqref{eq: control of martingale difference for local drift}, on $G_{n, K, t}$.

\begin{proof}[Proof of Lemma~\ref{lm:lipchitz-bound-on-good-event}]
	We verify this lemma for the case $y \ge  x > 0$. \TBD {\color{red} need to remark about other cases}.
	For notational simplicity, write $\alpha(i,j) := \left|\frac{-w(2 i + 1) + w(2 j)}{w(2i + 1) + w(2 j}\right|$. Then
\begin{equation*}
	\left| \Delta_y^{(x,m)} \right| 
	= 
	\left| 	\sum_{i = 0}^{\mathcal{E}_{y,+}^{(x,m)}} 
	\sum_{l = \tau_i^{\mathcal{B}}} ^{\tau_{i+1}^{\mathcal{B}}  -1}
	\alpha(\mathcal{B}_l, \mathcal{R}_l)
	\right| 
	\le 
	\sum_{i = 0}^{K \sqrt{n} } 
	\sum_{l = \tau_i^{\mathcal{B}}} ^{\tau_{i+1}^{\mathcal{B}}  -1}
	\left|
	\alpha(\mathcal{B}_l, \mathcal{R}_l)
	\right| 
\end{equation*}
and
\begin{align*}
	&\sum_{i = 0}^{K \sqrt{n} } 
	\sum_{l = \tau_i^{\mathcal{B}}} ^{\tau_{i+1}^{\mathcal{B}}  -1}
	|\alpha(\mathcal{B}_l, \mathcal{R}_l)|\\
	&\le C_w \sum_i \sum_l \left| \frac{1}{w(2 \mathcal{R}_l)} - \frac{1}{w(2 \mathcal{B}_l + 1)} \right|  \\
	&= C_w \sum_i \sum_l \left| \frac{1}{w(2 l - 2 i)} - \frac{1}{w(2i + 1)} \right|  \\
	&= C_w \sum_i \sum_{j = \tau_i^{\mathcal{B}} - i}^{\tau_{i+1}^{\mathcal{B}} - i - 1} \left| \frac{1}{w(2j)} - \frac{1}{w(2i + 1)} \right|  \\
	&= C_w \sum_i \sum_{j = \tau_i^{\mathcal{B}} - i}^{\tau_{i+1}^{\mathcal{B}} - i - 1} \left|  2^p B\left( \frac{1}{(2j)^p} - \frac{1}{(2i + 1)^p} \right)  + O\left( \frac{1}{i^{\kappa + 1}} \right) \right|  \\
	&\le C_w \sum_i \log^2 n \sup_{|j - i| \le 2 \sqrt{i}  \log^2 n} \left|  2^p B\left( \frac{1}{(2j)^p} - \frac{1}{(2i + 1)^p} \right)  + O\left( \frac{1}{i^{\kappa + 1}} \right) \right| \\
	&\le C_{w, p} \sum_i \log^2 n \left( 
		(4 \sqrt{ i } \log^2 n) (2 i - 2 \sqrt{ i } \log^2 n)^{- p - 1} + (2 i)^{- p - 1} + O(i^{- \kappa - 1})
	\right)  \\
	&\le C_{w, p} \sum_i \log^2 n \left( i ^{-p - \frac{1}{2}} \log^2 n +  i^{- \kappa - 1} \right)  \\
	&= C_{w, p} \sum_i i^{- p - \frac{1}{2}} \log^4 n + i^{- \kappa - 1 } \log^2 n \\
	&\stackrel{(p<\frac{1}{2})}{\le } C_{w, p} \left( (K \sqrt{ n} )^{-p+ \frac{1}{2}} \log^4 n + (K \sqrt{ n} )^{- \kappa } \log^2 n \right)  \\
	&= C_{w, p, K} n^{-\frac{1}{2}p + \frac{1}{4}  }  \log^4 n \qquad \text{assuming $\kappa$ small}
.\end{align*} 

{\color{red} Need some simplification and revision to make it more concise and cover all cases.}

\end{proof}



\subsection{Control of martingale Terms } 
\begin{proof}[Proof of Proposition~\ref{lm: control of martingale}]
It is already remarked earlier that we only need to obtain the control

\[
	 \lim_{N \to \infty } \frac{1}{N} \sum_{i = 0}^{N-1} \mathbb{E}\left[ X_{i+1} - X_i | \mathcal{F}_i \right]^2 = 0
.\] 


We can rewrite the sum into a sum of local drifts, and isolate the first $M$ visits:

\begin{align}
	&\sum_{i = 0}^{N-1} \mathbb{E}\left[ X_{i+1} - X_i | \mathcal{F}_i \right]^2\\
	&= \sum_{x \in \left[ I_N^X, S_N^X \right]} \sum_{i = 0}^{L_x(n) - 1} \mathbb{E}\left[ \mathcal{D}_{i+1}^{(x)} - \mathcal{D}_i^{(x)} | \mathcal{F}_{i}^{\mathcal{B}, \mathcal{R}} \right]^2  \\
	&\le  \sum_{x \in \left[ I_n^X, S_n^X \right]} \sum_{i = 0}^{L_x(N) - 1} \mathbb{E}\left[ \mathcal{D}_{i+1}^{(x)} - \mathcal{D}_i^{(x)} | \mathcal{F}_{i}^{\mathcal{B}, \mathcal{R}} \right]^2 \mathbf{1}\left( L_x(i) > M \right) + 
	\sum_{i = 0}^{N - 1} \mathbf{1}\left( L_{X_i}(i) \le  M \right) 
	\label{eqn:lem-martingale-1}
.\end{align}

We now restrict ourselves to the good event $G_{n, K, t}$ stated in \eqref{eqn:good-event-1}-\eqref{eqn:good-event-4}. Under $G$,
the inner sum in the first term is further controlled by
\begin{align*}
	&\sum_{i =0}^{ L_x(N) - 1} \mathbb{E}\left[ \mathcal{D}_{i+1}^{(x)} - \mathcal{D}_i^{(x)} | \mathcal{F}_{i}^{\mathcal{B}, \mathcal{R}} \right]^2 \mathbf{1}\left( L_{x}(i) > M \right) \\
	&\stackrel{(x > 0)}{\le} C_w \sum_{i = M}^{\mathcal{B}_N} \sum_{l = \tau_i^{\mathcal{B}}}^{\tau_{i+1}^{\mathcal{B}}-1} 
	\left| \frac{1}{w(2 \mathcal{R}_l)} - \frac{1}{w\left( 2 \mathcal{B}_l + 1 \right) } \right|^2 \\
	&\le C_{w, p} \sum_i i^{- 2 p - 1} \log^3 n \\
	\intertext{\color{red} \TBD need to fix the number of logs. Good event $G_{n, K, t}$ need to be handled more carefully.}
	&\le C_{w, p} \left[ M^{- 2 p} - \mathcal{B}_N^{- 2 p} \right] \log^3 N  \\
	&< C_{w, p} M^{-2 p} \log^3 N
	.
\end{align*}

Note that this bound is uniform in $x$. We remark that cases $(x=0)$ and $(x < 0)$ have the exactly same bounds. 

Now apply the bound $\sum_{i = 0}^{n-1} \mathbf{1}\left( L_{X_i}(i) \le M \right) \mathbf{1}(X_i = x) \le  M$ to the second term in \eqref{eqn:lem-martingale-1}, we have

\begin{multline}
	\sum_{x \in \left[ I_N^X, S_N^X \right]} \sum_{i = 0}^{L_x(N) - 1} \mathbb{E}\left[ \mathcal{D}_{i+1}^{(x)} - \mathcal{D}_i^{(x)} | \mathcal{F}_{i}^{\mathcal{B}, \mathcal{R}} \right]^2 \\
	< \sum_{x \in \left[ I_N^X, S_N^X \right]} (C_{w, p} M^{-2p} \log^3 N +M )
\end{multline}

Using process-level tightness, the summation only add a term of order $\sqrt{N}$, on a good event. Since we have a factor of $\frac{1}{N}$, and $M$ independent of $N$, we have the right hand side $\to 0$. More precisely,

\begin{align*}
	 &P\left( \left| \frac{1}{N} \sum_{i = 0}^{N-1} \mathbb{E}\left[ X_{i+1} - X_i | \mathcal{F}_i \right]^2  \right|  > \varepsilon \right)\\
	 &\le P\left( \left| \sum_{x \in \left[ I_N^X, S_N^X \right]} (C_{w, p} M^{-2p} \log^3 N +M ) \right| > \varepsilon  N \right) + P(G^c) \\
	 &\le 2 P\left( S_N^X \ge n^{3 / 4} \right) + P\left(  \left| \sum_{|x| \le N^{3 / 4}} (C_{w, p} M^{-2p} \log^3 n +M ) \right| > \varepsilon  n  \right) +P(G^c)  \\
	 &\le 2 P\left( S_N^X \ge n^{3 / 4} \right) + P\left(  C_{w, p, M} \,\, N^{3 / 4} \log^3 N > \varepsilon  N  \right) + P(G^c)
.\end{align*}
The second term vanishes trivially; the first term vanishes by process-level tightness of $S_N^X / \sqrt{N} $. The last term goes to zero as shown in the previous section.
\end{proof}

\begin{thebibliography}{99}\addcontentsline{toc}{chapter}{Bibliography} 
 \bibitem[KMP22]{KMP22} Kosygina,~E., Mountford,~T., Peterson,~J.: Convergence and Non-Convergence of Scaled Self-Interacting Random Walks to Brownian Motion Perturbed at Extrema. \textit{arXiv:2208.02589,} 2022.
 
 \bibitem[KP16]{KP16} Kosygina,~E., Peterson,~J.: Functional limit laws for recurrent excited random walks with
 periodic cookie stacks. \textit{Electron. J. Probab.} \textbf{21} 2016.

\bibitem[L23]{L23} Liu,~X.: Research in Random Walk. \textit{Personal communication,} 2023.

\bibitem[T96]{T96} T\'{o}th,~B.: Generalized Ray-Knight theory and limit theorems for self-interacting random walks on $\mathbb{Z}^1$ \textit{Ann. Probab.} \textbf{24} 1324--1367. 1996
\end{thebibliography}
\end{document}
